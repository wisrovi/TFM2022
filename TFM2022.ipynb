{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wisrovi/TFM2022/blob/main/TFM2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQgcFJXmeJCA"
      },
      "source": [
        "# Autor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZBzD5cTefM_"
      },
      "source": [
        "Autor: William S. Rodriguez V.\n",
        "\n",
        "Link colab: https://colab.research.google.com/drive/1KSSPwElIl1MZnMRn0XdXlJPlcGh-i1ST#scrollTo=dv_hLoOBFj33\n",
        "\n",
        "Github: https://github.com/wisrovi/TFM2022"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "p9W0zOu3F1I5",
        "outputId": "284e1330-026d-4a51-fedb-c13a05cfe8c7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "\n",
              "<!--  https://ghlinkcard.com/  -->\n",
              "<a href=\"https://github.com/wisrovi/TFM2022\">\n",
              "<img src=\"https://github-link-card.s3.ap-northeast-1.amazonaws.com/wisrovi/TFM2022.png\" width=\"460px\">\n",
              "</a> \n",
              "<br/>\n",
              "<a href=\"https://profile-summary-for-github.com/user/wisrovi\">Estadisticas Repo</a>\n",
              "\n",
              "<br/>\n",
              "<br/>\n",
              "<br/>\n",
              "<br/>\n",
              "<br/>\n",
              "\n",
              "<script src=\"https://platform.linkedin.com/badges/js/profile.js\" \n",
              "async defer type=\"text/javascript\"></script>\n",
              "<div class=\"badge-base LI-profile-badge\" data-locale=\"es_ES\" data-size=\"large\" \n",
              "data-theme=\"dark\" data-type=\"HORIZONTAL\" data-vanity=\"wisrovi-rodriguez\" \n",
              "data-version=\"v1\"><a class=\"badge-base__link LI-simple-link\" \n",
              "href=\"https://co.linkedin.com/in/wisrovi-rodriguez?trk=profile-badge\">William Rodriguez</a></div>\n",
              "\n",
              "\n",
              "<br/>\n",
              "<br/>\n",
              "<br/>\n",
              "<br/>\n",
              "<br/>\n",
              "\n",
              "\n",
              "<iframe src=\"https://kaggle-card.chienhsiang-hung.eu.org/api/basic?wisrovi\" \n",
              "width=\"62%\" height=\"280\" style=\"border:none; min-width: 80px;\"></iframe>\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Autor\n",
        "\n",
        "%%html\n",
        "\n",
        "\n",
        "\n",
        "<!--  https://ghlinkcard.com/  -->\n",
        "<a href=\"https://github.com/wisrovi/TFM2022\">\n",
        "<img src=\"https://github-link-card.s3.ap-northeast-1.amazonaws.com/wisrovi/TFM2022.png\" width=\"460px\">\n",
        "</a> \n",
        "<br/>\n",
        "<a href=\"https://profile-summary-for-github.com/user/wisrovi\">Estadisticas Repo</a>\n",
        "\n",
        "<br/>\n",
        "<br/>\n",
        "<br/>\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "<script src=\"https://platform.linkedin.com/badges/js/profile.js\" \n",
        "async defer type=\"text/javascript\"></script>\n",
        "<div class=\"badge-base LI-profile-badge\" data-locale=\"es_ES\" data-size=\"large\" \n",
        "data-theme=\"dark\" data-type=\"HORIZONTAL\" data-vanity=\"wisrovi-rodriguez\" \n",
        "data-version=\"v1\"><a class=\"badge-base__link LI-simple-link\" \n",
        "href=\"https://co.linkedin.com/in/wisrovi-rodriguez?trk=profile-badge\">William Rodriguez</a></div>\n",
        "\n",
        "\n",
        "<br/>\n",
        "<br/>\n",
        "<br/>\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "\n",
        "<iframe src=\"https://kaggle-card.chienhsiang-hung.eu.org/api/basic?wisrovi\" \n",
        "width=\"62%\" height=\"280\" style=\"border:none; min-width: 80px;\"></iframe>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nM2zJ-rO_7ol"
      },
      "source": [
        "# 0. Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WDJQ7yBqyql7"
      },
      "outputs": [],
      "source": [
        "#@title basic config\n",
        "FOLDER_OUT = \"/gdrive/MyDrive/TFM/\"\n",
        "FOLDER_INT = \"musicnet/musicnet\"\n",
        "\n",
        "USE_COLAB = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HTybUQo5Q5Ji"
      },
      "outputs": [],
      "source": [
        "#@title CONFIG\n",
        "#@markdown Configuracion del sistema.\n",
        "#@markdown ---\n",
        "#@markdown ---\n",
        "\n",
        "porcentaje_PCA = 93  #@param {type: \"slider\", min: 80, max: 98}\n",
        "tiempo_split = 2  #@param {type: \"slider\", min: 1, max: 12}\n",
        "porcentaje_split_train_valid = 20  #@param {type: \"slider\", min: 10, max: 35}\n",
        "#@markdown ---\n",
        "procesar_data_kaggle = False #@param {type: \"boolean\"} \n",
        "aplicar_data_incrementation = True #@param {type: \"boolean\"} \n",
        "refit = True #@param {type: \"boolean\"} \n",
        "#@markdown ---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LZqM3V_W8kjr"
      },
      "outputs": [],
      "source": [
        "#@title CONFIG\n",
        "\n",
        "MINIMA_VARIANA_EXPLICADA = 0.93 if not USE_COLAB else porcentaje_PCA/100 # se debe definir porque este valor\n",
        "TIME_SPLIT = 1 if not USE_COLAB else tiempo_split # falta definir porque este split de 2\n",
        "\n",
        "# Folder\n",
        "FOLDER_SAVE_NORMALIZADOR_PCA = FOLDER_OUT + f'normalizador_pca_{str(TIME_SPLIT)}seg.pkl'\n",
        "FOLDER_MODEL = FOLDER_OUT + f\"randomforest_{str(TIME_SPLIT)}seg.pkl\"\n",
        "\n",
        "FOLDER_TRAIN_DATA = FOLDER_OUT + f\"train_data_{str(TIME_SPLIT)}seg.csv\"\n",
        "FOLDER_TRAIN_LABEL = FOLDER_OUT + f\"train_label_{str(TIME_SPLIT)}seg.csv\"\n",
        "FOLDER_TEST_DATA = FOLDER_OUT + f\"test_data_{str(TIME_SPLIT)}seg.csv\"\n",
        "FOLDER_TEST_LABEL = FOLDER_OUT + f\"test_label_{str(TIME_SPLIT)}seg.csv\"\n",
        "\n",
        "FOLDER_LABEL = FOLDER_OUT + \"all_label.csv\"\n",
        "\n",
        "# Model\n",
        "SPLIT_DATA_TRAIN = 0.2 if not USE_COLAB else porcentaje_split_train_valid/100 \n",
        "\n",
        "EXTRACT_DATA_AUDIOS = False if not USE_COLAB else procesar_data_kaggle \n",
        "FIND_DATA_INCREMENT = True if not USE_COLAB else aplicar_data_incrementation \n",
        "REFIT = True if not USE_COLAB else refit "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWn-7Bgt11dz"
      },
      "source": [
        "# 1. Obtener la llave de kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s_isdcaz3OC",
        "outputId": "72101cf9-d23a-4f4f-9926-2fc32b25bae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcZRjkWPyqZj"
      },
      "outputs": [],
      "source": [
        "if EXTRACT_DATA_AUDIOS:\n",
        "    # Creamos carpeta oculta en ambiente de linux sobre colab\n",
        "    !mkdir ~/.kaggle\n",
        "\n",
        "    # Copiar el archivo JSON  a la carpeta oculta que creamos\n",
        "    !cp '/gdrive/MyDrive/TFM/kaggle.json' ~/.kaggle/\n",
        "\n",
        "    # Cambiamos los permisos para permitir lectura de las credenciales\n",
        "    !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSZNQ2L61-Hp"
      },
      "source": [
        "# 2. Instalando librerias faltantes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dv_hLoOBFj33"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "!pip install pyspark\n",
        "!pip install nlpaug===1.1.11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfFC9wM9bOl3"
      },
      "source": [
        "# 3. Importando recursos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9cXOup1Nb1g",
        "outputId": "696c7b8d-91c3-4953-f070-1df85986a18b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current vers 0.8.1\n"
          ]
        }
      ],
      "source": [
        "#@title validando librosa\n",
        "try:\n",
        "    import librosa\n",
        "except:\n",
        "    # !pip uninstall --yes librosa\n",
        "    !pip install librosa===0.7.2 --force-reinstall\n",
        "import librosa\n",
        "print(\"current vers\", librosa.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kpUn5ZEmyqhg"
      },
      "outputs": [],
      "source": [
        "#@title librerias para preprocesamiento de datos\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "import numpy as np\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6tw3CG8W8uIK"
      },
      "outputs": [],
      "source": [
        "#@title librerias para modelado y entrenamiento\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import sklearn.metrics as metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hU-4uzUyyqjn"
      },
      "outputs": [],
      "source": [
        "#@title librerias para bigdata\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ORIu3KWy9FM6"
      },
      "outputs": [],
      "source": [
        "#@title libreria para split de audio\n",
        "import scipy.io.wavfile as wav\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class Corte_audio():\n",
        "    SEGUNDOS_CORTE = 5\n",
        "\n",
        "    def __init__(self, config_time: int = 5, save_audios: str = None):\n",
        "        self.SEGUNDOS_CORTE = config_time\n",
        "        self.save_audios = save_audios\n",
        "\n",
        "    def __hallar_instrumentos(self, corte_start, corte_end, instrument, start_time):\n",
        "        acumulador = list()\n",
        "        for (i, time_start) in enumerate(start_time):\n",
        "            if corte_end >= start_time[i] >= corte_start:\n",
        "                # print(start_time[i], end_time[i], instrument[i])\n",
        "                if not instrument[i] in acumulador:\n",
        "                    acumulador.append(instrument[i])\n",
        "            else:\n",
        "                if time_start > corte_end:\n",
        "                    break\n",
        "        return acumulador\n",
        "\n",
        "    def ___save_data(self, data_save, file):\n",
        "        df = pd.DataFrame(data=data_save, columns=['instrument'], index=None, dtype=None, copy=False)\n",
        "        df.to_csv(file, index=False)\n",
        "\n",
        "    def split_data(self, path_wav: str = \"\", path_csv: str = \"\", tag: str = \"dat\"):\n",
        "        (rate, sig) = wav.read(path_wav)\n",
        "        labels = pd.read_csv(path_csv)\n",
        "\n",
        "        instrument = labels['instrument']\n",
        "        start_time = labels['start_time']\n",
        "\n",
        "        pivote = 0\n",
        "        corte = rate * self.SEGUNDOS_CORTE\n",
        "\n",
        "        muestras = list()\n",
        "        instrumentos = list()\n",
        "        for _ in range(round(len(sig) / corte)):\n",
        "            corte_start, corte_end = pivote, pivote + corte\n",
        "            data = sig[corte_start:corte_end]\n",
        "            muestras.append(data)\n",
        "            instrumentos.append(self.__hallar_instrumentos(corte_start, corte_end, instrument, start_time))\n",
        "            pivote += corte\n",
        "\n",
        "        if pivote < len(sig):\n",
        "            data = sig[pivote:]\n",
        "            muestras.append(data)\n",
        "            instrumentos.append(self.__hallar_instrumentos(pivote, len(sig), instrument, start_time))\n",
        "\n",
        "        if self.save_audios is not None:\n",
        "            for i, data in enumerate(muestras):\n",
        "                wav.write(self.save_audios + f\"{tag}_{i}.wav\", rate, data)\n",
        "                self.___save_data(instrumentos[i], self.save_audios + f\"{tag}_{i}.csv\")\n",
        "\n",
        "        return muestras, instrumentos, rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xjOvyxx894Ki"
      },
      "outputs": [],
      "source": [
        "#@title libreria para extraccion de caracteristicas\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class ProcessAudio(object):\n",
        "    data = None\n",
        "\n",
        "    def __init__(self, sr:int = 44100):\n",
        "        self.mfcc = None\n",
        "        self.zcr = None\n",
        "        self.rolloff = None\n",
        "        self.spec_bw = None\n",
        "        self.spec_cent = None\n",
        "        self.rmse = None\n",
        "        self.chroma_stft = None\n",
        "        self.sr = sr\n",
        "\n",
        "    def set_data(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def display_waveform(self):\n",
        "        if self.data is None:\n",
        "            return None\n",
        "        # display waveform\n",
        "        plt.figure(figsize=(14, 5))\n",
        "        librosa.display.waveplot(self.data , sr=self.sr)\n",
        "\n",
        "    def get_croma(self):\n",
        "        if self.data is None:\n",
        "            return None\n",
        "        self.chroma_stft = librosa.feature.chroma_stft(y=self.data, sr=self.sr)\n",
        "        return self.chroma_stft\n",
        "\n",
        "    def get_rmse(self):\n",
        "        if self.data is None:\n",
        "            return None\n",
        "        self.rmse = librosa.feature.rms(y=self.data)\n",
        "        return self.rmse\n",
        "\n",
        "    def get_centroide_espectral(self):\n",
        "        \"\"\"centroide espectral\"\"\"\n",
        "        if self.data is None:\n",
        "            return None\n",
        "        self.spec_cent = librosa.feature.spectral_centroid(y=self.data, sr=self.sr)\n",
        "        return self.spec_cent\n",
        "\n",
        "    def get_ancho_banda_espectral(self):\n",
        "        if self.data is None:\n",
        "            return None\n",
        "        self.spec_bw = librosa.feature.spectral_bandwidth(y=self.data, sr=self.sr)\n",
        "        return self.spec_bw\n",
        "\n",
        "    def get_rolloff(self):\n",
        "        \"\"\"tambien conocido como reduccion espectral\"\"\"\n",
        "        if self.data is None:\n",
        "            return None\n",
        "        self.rolloff = librosa.feature.spectral_rolloff(y=self.data, sr=self.sr)\n",
        "        return self.rolloff\n",
        "\n",
        "    def get_cruce_por_cero(self):\n",
        "        if self.data is None:\n",
        "            return None\n",
        "        self.zcr = librosa.feature.zero_crossing_rate(self.data)\n",
        "        return self.zcr\n",
        "\n",
        "    def get_mfcc(self):\n",
        "        if self.data is None:\n",
        "            return None\n",
        "        self.mfcc = librosa.feature.mfcc(y=self.data, sr=self.sr)\n",
        "        return self.mfcc\n",
        "\n",
        "    def get_all(self, i:int) -> list:\n",
        "        if self.data is None:\n",
        "            return []\n",
        "\n",
        "        self.get_croma()\n",
        "        self.get_rmse()\n",
        "        self.get_centroide_espectral()\n",
        "        self.get_ancho_banda_espectral()\n",
        "        self.get_rolloff()\n",
        "        self.get_cruce_por_cero()\n",
        "        self.get_mfcc()\n",
        "\n",
        "        data_compresed = f'train{i} {np.mean(self.chroma_stft)} {np.mean(self.rmse)} {np.mean(self.spec_cent)} {np.mean(self.spec_bw)} {np.mean(self.rolloff)} {np.mean(self.zcr)}'\n",
        "        for e in self.mfcc:\n",
        "            data_compresed += f' {np.mean(e)}'\n",
        "\n",
        "        return data_compresed.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0hG2DWJAD8cE"
      },
      "outputs": [],
      "source": [
        "#@title libreria para aumento de datos de audio\n",
        "\n",
        "import nlpaug.augmenter.audio as naa\n",
        "import librosa.display as librosa_display\n",
        "\n",
        "\n",
        "class AudioAugmentation:\n",
        "    graph: bool = False\n",
        "    print_middleware: bool = False\n",
        "\n",
        "    def __init__(self, audio_file, graph=False, save: str = None):\n",
        "        self.audio_file = audio_file\n",
        "        self.graph = graph\n",
        "        self.save = save\n",
        "        if isinstance(audio_file, str):\n",
        "            print(\"Cargando archivo de audio\")\n",
        "            self.name_file = audio_file.split(\".\")[-2].split(\"/\")[-1]\n",
        "            self.data, self.rate = self.__read_audio_file(self.audio_file)\n",
        "        elif isinstance(audio_file, tuple):\n",
        "            #print(\"Audio file is a tuple\")\n",
        "            self.data, self.rate, self.name_file = audio_file\n",
        "            #print(len(self.data), self.rate, self.name_file)\n",
        "\n",
        "    def middleware_in(atributo1: str = \"\", ):\n",
        "        def _middleware_in(f):\n",
        "            def wrapper(self, *args, **kwargs):\n",
        "                # ejecucion antes de ejecutar la funcion\n",
        "                if self.print_middleware:\n",
        "                    print(f\"Middleware in {f.__name__} ({atributo1})\")\n",
        "\n",
        "                # ejecucion de la funcion\n",
        "                ejecucion_ok = True\n",
        "                try:\n",
        "                    salida = f(self, *args, **kwargs)\n",
        "                except Exception as e:\n",
        "                    ejecucion_ok = False\n",
        "                    salida = e\n",
        "                    print(f\"Error en la ejecucion de la funcion {f.__name__}: {e}\")\n",
        "\n",
        "                # ejecucion despues de ejecutar la funcion\n",
        "                if ejecucion_ok:\n",
        "                    if self.graph:\n",
        "                        self.plot_audio(salida)\n",
        "\n",
        "                    if self.save is not None:\n",
        "                        try:\n",
        "                            if isinstance(salida, list):\n",
        "                                if self.print_middleware:\n",
        "                                    print(salida)\n",
        "                                salida = np.array(salida)\n",
        "                            self.write_audio_file(self.save + self.name_file + \"_\" + f\"{f.__name__}.wav\", salida, self.rate)\n",
        "                        except Exception as e:\n",
        "                            if self.print_middleware:\n",
        "                                print(f\"Error al guardar el archivo: {e}\")\n",
        "                            print(type(salida))\n",
        "\n",
        "                return salida\n",
        "\n",
        "            return wrapper\n",
        "\n",
        "        return _middleware_in\n",
        "\n",
        "    def plot_audio(self, data2=None):\n",
        "        librosa_display.waveshow(self.data, sr=self.rate, alpha=0.5)\n",
        "        if data2 is not None:\n",
        "            librosa_display.waveshow(data2, sr=self.rate, color='r', alpha=0.25)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    @middleware_in(atributo1=\"loudness_f\")\n",
        "    def loudness(self):\n",
        "        aug = naa.LoudnessAug()\n",
        "        augmented_data = aug.augment(self.data)[0]\n",
        "        return augmented_data\n",
        "\n",
        "    @middleware_in(atributo1=\"mask_f\")\n",
        "    def add_mask(self):\n",
        "        aug = naa.MaskAug(sampling_rate=self.rate, mask_with_noise=False)\n",
        "        augmented_data = aug.augment(self.data)[0]\n",
        "        return augmented_data\n",
        "\n",
        "    @middleware_in(atributo1=\"pitch_f\")\n",
        "    def pitch(self, fact=(2,3)):\n",
        "        aug = naa.PitchAug(sampling_rate=self.rate, factor=fact)\n",
        "        augmented_data = aug.augment(self.data)[0]\n",
        "        return augmented_data\n",
        "\n",
        "    @middleware_in(atributo1=\"original\")\n",
        "    def get_original(self):\n",
        "        return self.data\n",
        "\n",
        "    @middleware_in(atributo1=\"crop\")\n",
        "    def add_crop(self, porcentaje: float = 0.5):\n",
        "        crop = naa.CropAug(sampling_rate=self.rate)\n",
        "        augmented_data = crop.augment(self.data)[0]\n",
        "        return augmented_data\n",
        "\n",
        "    @staticmethod\n",
        "    def __read_audio_file(file_path):\n",
        "        input_length = 16000\n",
        "        data, rate = librosa.core.load(file_path)\n",
        "        if len(data) > input_length:\n",
        "            data = data[:input_length]\n",
        "        else:\n",
        "            data = np.pad(data, (0, max(0, input_length - len(data))), \"constant\")\n",
        "        return data, rate\n",
        "\n",
        "    @staticmethod\n",
        "    def write_audio_file(file, data, sample_rate):\n",
        "        write(file, sample_rate, data)\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_time_series(data):\n",
        "        fig = plt.figure(figsize=(14, 8))\n",
        "        plt.title('Raw wave ')\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.plot(np.linspace(0, 1, len(data)), data)\n",
        "        plt.show()\n",
        "\n",
        "    @middleware_in(atributo1=\"ruido\")\n",
        "    def add_noise(self, factor_ruido=0.005):\n",
        "        noise = np.random.randn(len(self.data))\n",
        "        data_noise = self.data + factor_ruido * noise\n",
        "        data_noise = data_noise.astype(type(self.data[0]))  # Cast back to same\n",
        "        return data_noise\n",
        "\n",
        "    @middleware_in(atributo1=\"ruido2\")\n",
        "    def add_noise2(self):\n",
        "        aug = naa.NoiseAug()\n",
        "        augmented_data = aug.augment(self.data)[0]\n",
        "        return augmented_data\n",
        "\n",
        "    @middleware_in(atributo1=\"shift\")\n",
        "    def shift(self):\n",
        "        return np.roll(self.data, 1600)\n",
        "\n",
        "    @middleware_in(atributo1=\"stretch\")\n",
        "    def stretch(self, rate_stretch=1.0):\n",
        "        input_length = 16000\n",
        "        data = librosa.effects.time_stretch(self.data, rate=rate_stretch)\n",
        "        if len(data) > input_length:\n",
        "            data = data[:input_length]\n",
        "        else:\n",
        "            data = np.pad(data, (0, max(0, input_length - len(data))), \"constant\")\n",
        "        return data\n",
        "\n",
        "    @middleware_in(atributo1=\"speed\")\n",
        "    def speed(self):\n",
        "        aug = naa.SpeedAug()\n",
        "        augmented_data = aug.augment(self.data)[0]\n",
        "        return augmented_data\n",
        "\n",
        "    @middleware_in(atributo1=\"normalizador\")\n",
        "    def normalizer(self):\n",
        "        aug = naa.NormalizeAug(method='minmax')\n",
        "        augmented_data = aug.augment(self.data)[0]\n",
        "        return augmented_data\n",
        "\n",
        "    @middleware_in(atributo1=\"polarizador\")\n",
        "    def polarizer(self):\n",
        "        aug = naa.PolarityInverseAug()\n",
        "        augmented_data = aug.augment(self.data)[0]\n",
        "        return augmented_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-H1XG_oVEMD-"
      },
      "outputs": [],
      "source": [
        "#@title libreria para cargar los audios, preprocesarlos y montarlos en matrix numpy\n",
        "class Audio_K(AudioAugmentation):\n",
        "\n",
        "    def __init__(self, file_path, label: list, save: str = None, grafica: bool = False):\n",
        "        super().__init__(file_path, save=save, graph=grafica)\n",
        "        self.label = label\n",
        "\n",
        "    def aumentar(self):\n",
        "        all_data = [\n",
        "            self.get_original(),\n",
        "            self.add_noise(factor_ruido=0.05),\n",
        "            self.add_noise2(),\n",
        "            self.stretch(rate_stretch=0.8),\n",
        "            self.shift(),\n",
        "            self.add_crop(),\n",
        "            self.loudness(),\n",
        "            self.speed(),\n",
        "            self.normalizer(),\n",
        "            self.polarizer()\n",
        "        ]\n",
        "\n",
        "        all_label = [self.label for _ in range(len(all_data))]\n",
        "        return all_data, all_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "g60-jVkkEO_h"
      },
      "outputs": [],
      "source": [
        "#@title funcion para conteo tiempo de ejecucion de una funcion\n",
        "from functools import wraps\n",
        "from time import time\n",
        "\n",
        "\n",
        "def count_elapsed_time(f):\n",
        "    @wraps(f)\n",
        "    def cronometro(*args, **kwargs):\n",
        "        t_inicial = time()  # tomo la hora antes de ejecutar la funcion\n",
        "        salida = f(*args, **kwargs)\n",
        "        t_final = time()  # tomo la hora despues de ejecutar la funcion\n",
        "        print('Tiempo transcurrido (en segundos): {}'.format(t_final - t_inicial))\n",
        "        return salida\n",
        "\n",
        "    return cronometro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "paBD4KAM8zAC"
      },
      "outputs": [],
      "source": [
        "#@title evitar que el cuaderno muestre alertas innecesarias\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTUZ6mIBbXTy"
      },
      "source": [
        "# 4. Clonando los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzmA1fTMyqbi",
        "outputId": "36c49ebb-0124-4713-e1c8-5bcd519d7ec0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No se clonan los datos de kaggle porque la opcion esta deshabilitada en la configuración\n"
          ]
        }
      ],
      "source": [
        "#@title descargo los datos de kaggle\n",
        "if EXTRACT_DATA_AUDIOS:\n",
        "    # Descargamos archivos indicando el usuario del propietario de los datos en kaggle y el nombre de dataset\n",
        "    ! kaggle datasets download imsparsh/musicnet-dataset --force\n",
        "else:\n",
        "    print(\"No se clonan los datos de kaggle porque la opcion esta deshabilitada en la configuración\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iZ-zeViKyqdj"
      },
      "outputs": [],
      "source": [
        "#@title descomprimo los datos descargados de kaggle\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "if EXTRACT_DATA_AUDIOS:\n",
        "    # Descomprimir el archivo de kaggle\n",
        "    for file in os.listdir():\n",
        "        if file.endswith('.zip'):\n",
        "            zip_ref = zipfile.ZipFile(file, 'r')\n",
        "            zip_ref.extractall()\n",
        "            zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "geW5ENYUyqfj"
      },
      "outputs": [],
      "source": [
        "#@title elimino el archivo original, pues ya no es necesario luego de descomprimir\n",
        "if EXTRACT_DATA_AUDIOS:\n",
        "    !rm musicnet-dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTKF6TIc7KpJ"
      },
      "source": [
        "# 5. Preprocesando los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJ633kQ08zJ4"
      },
      "outputs": [],
      "source": [
        "# Iniciar conexión de spark para analizar con bigdata los datos luego de preprocesarlos\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHjAmaQGbkNH"
      },
      "source": [
        "# 5.1. pipeline y funciones para preprocesar los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCmbeolz8klo"
      },
      "outputs": [],
      "source": [
        "# iniciador de clases\n",
        "\n",
        "pca_pipe = make_pipeline(StandardScaler(), PCA(MINIMA_VARIANA_EXPLICADA))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtiMVTQg8knm"
      },
      "outputs": [],
      "source": [
        "if EXTRACT_DATA_AUDIOS:\n",
        "    # organizando los datos en train y test (data y label para cada uno)\n",
        "\n",
        "    TRAIN = {}\n",
        "    TEST = {}\n",
        "\n",
        "    @count_elapsed_time\n",
        "    def crear_diccionarios_train_test():\n",
        "        for dirname, _, filenames in os.walk(FOLDER_INT):\n",
        "            for filename in filenames:\n",
        "                file = os.path.join(dirname, filename)\n",
        "                name_file, extension = filename.split(\".\")\n",
        "\n",
        "                if extension == \"csv\" or extension == \"wav\":\n",
        "                    if dirname.find(\"train\")>0:\n",
        "                        if name_file not in TRAIN:\n",
        "                            TRAIN[name_file] = {}\n",
        "                        if filename.find(\"csv\")>0:\n",
        "                            TRAIN[name_file]['label'] = file\n",
        "                        else:\n",
        "                            TRAIN[name_file]['data'] = file\n",
        "                    else:\n",
        "                        if name_file not in TEST:\n",
        "                            TEST[name_file] = {}\n",
        "                        if filename.find(\"csv\")>0:\n",
        "                            TEST[name_file]['label'] = file\n",
        "                        else:\n",
        "                            TEST[name_file]['data'] = file\n",
        "    crear_diccionarios_train_test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZflijTW8ktZ"
      },
      "outputs": [],
      "source": [
        "def save_data(data_save, file):\n",
        "    df = pd.DataFrame(data=data_save)\n",
        "    df.to_csv(file)\n",
        "\n",
        "def read_data(file, to_numpy: bool = False):\n",
        "    df = spark.read.csv(file, \n",
        "                        header=True,\n",
        "                        mode=\"DROPMALFORMED\",)\n",
        "    df_pandas = df.toPandas()\n",
        "    df_pandas = df_pandas.drop('_c0', axis=1)\n",
        "    if to_numpy:\n",
        "        df_pandas = df_pandas.to_numpy()\n",
        "    return df, df_pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIMo_HCq8kpc",
        "outputId": "f9cb983f-ea66-49ae-92f7-65dc56dd2d4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('1', '7', '41', '42', '43', '44', '61', '69', '71', '72', '74')\n"
          ]
        }
      ],
      "source": [
        "if EXTRACT_DATA_AUDIOS:\n",
        "    TODOS_LABEL = {}\n",
        "else:\n",
        "    TODOS_LABEL = read_data(FOLDER_LABEL, to_numpy=True)[1]\n",
        "    TODOS_LABEL = tuple([ d[0] for d in TODOS_LABEL.tolist()])\n",
        "    print(TODOS_LABEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWx-x6v98krT"
      },
      "outputs": [],
      "source": [
        "@count_elapsed_time\n",
        "def files_to_data(diccionario_datos, buscar_todos_label: bool = False, save_new_data: str = None, data_aumentation: bool = False):\n",
        "    global TODOS_LABEL\n",
        "    conteo = 0\n",
        "    conteo2 = 0\n",
        "\n",
        "    DATA = []\n",
        "    LABEL = []\n",
        "\n",
        "    rate = 0\n",
        "\n",
        "    cortador = Corte_audio(config_time=TIME_SPLIT, save_audios=save_new_data)\n",
        "\n",
        "    for name_file, value in diccionario_datos.items():\n",
        "        if 'data' in value and 'label' in value:\n",
        "            conteo += 1\n",
        "            conteo2 += 1\n",
        "            print(f\"{name_file}({conteo2})\", end=\" - \")\n",
        "            if conteo >= 20:\n",
        "                print()\n",
        "                conteo = 0\n",
        "\n",
        "            muestras_wav, instrumentos, rate = cortador.split_data(value['data'], value['label'])\n",
        "\n",
        "            if data_aumentation and buscar_todos_label:\n",
        "                new_muestras = []\n",
        "                new_instruments = []\n",
        "                for id_audio, dat in enumerate(muestras_wav):\n",
        "                    data_audio_para_amplificar= (dat, rate, \"data_\" + str(id_audio))\n",
        "                    label_audio_para_amplificar = instrumentos[id_audio]\n",
        "                    data_amplificada, label_amplificada = Audio_K(data_audio_para_amplificar, label=label_audio_para_amplificar).aumentar()\n",
        "                    #print(len(data_amplificada))\n",
        "                    for id_new_audio, new_audio in enumerate(data_amplificada):\n",
        "                        new_data_add = new_audio\n",
        "                        new_label_add = label_amplificada[id_new_audio]\n",
        "\n",
        "                        ok = True\n",
        "                        try:\n",
        "                            cte = 110250\n",
        "                            if (TIME_SPLIT*rate) > len(new_data_add):\n",
        "                                new_data_add += [0 for _ in range(cte*TIME_SPLIT)]\n",
        "                            if (TIME_SPLIT*rate) < len(new_data_add):\n",
        "                                new_data_add = new_data_add[:TIME_SPLIT*cte]\n",
        "                        except Exception as e:\n",
        "                            ok = False\n",
        "\n",
        "                        if ok:\n",
        "                            new_muestras.append(new_data_add)\n",
        "                            new_instruments.append(new_label_add)\n",
        "\n",
        "                muestras_wav, instrumentos = new_muestras, new_instruments\n",
        "\n",
        "            processAudio = ProcessAudio(rate)\n",
        "            for id_audio, dat in enumerate(muestras_wav):\n",
        "                processAudio.set_data(dat)\n",
        "                # print(len(dat), end = \">\")\n",
        "                ok = True\n",
        "                caracteristicas = None\n",
        "                try:\n",
        "                    caracteristicas = processAudio.get_all(id_audio)  # Extrayendo caracteristicas audios, salen 26 caracteristicas\n",
        "                except:\n",
        "                    ok = False\n",
        "                if ok:\n",
        "                    DATA.append(caracteristicas[1:])\n",
        "                    LABEL.append(instrumentos[id_audio])\n",
        "\n",
        "    # buscando todos los label\n",
        "    if buscar_todos_label:\n",
        "        for lab in LABEL:\n",
        "            for la in lab:\n",
        "                if la not in TODOS_LABEL:\n",
        "                    TODOS_LABEL[la] = 0\n",
        "        TODOS_LABEL = tuple(sorted(TODOS_LABEL))\n",
        "        save_data(data_save=TODOS_LABEL, file=FOLDER_LABEL)\n",
        "\n",
        "    # expandiendo los label a su respectivo vector de etiquetas\n",
        "    for j, lab in enumerate(LABEL):\n",
        "        new_label = [0 for _ in TODOS_LABEL]\n",
        "        for la in lab:\n",
        "            for i, l in enumerate(TODOS_LABEL):\n",
        "                if l == la:\n",
        "                    new_label[i] = 1\n",
        "        LABEL[j] = new_label\n",
        "\n",
        "\n",
        "    # convirtiendo a numpy los datos\n",
        "    DATA = np.array(DATA, dtype=float)\n",
        "    LABEL = np.array(LABEL, dtype=float)\n",
        "\n",
        "    return DATA, LABEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDjsV29yE53Z"
      },
      "outputs": [],
      "source": [
        "mean = lambda lst: int((sum(lst) / len(lst)) * 100) / 100\n",
        "\n",
        "def calcular_porcentajes_aciertos(y_f, y_t):\n",
        "    verdaderos = dict()\n",
        "    falsos = dict()\n",
        "    for j in range(y_f.shape[1]):\n",
        "        verdaderos[j] = 0\n",
        "        falsos[j] = 0\n",
        "\n",
        "    for i in range(y_f.shape[0]):\n",
        "        for j in range(y_f.shape[1]):\n",
        "            if y_f[i][j] == y_t[i][j]:\n",
        "                verdaderos[j] += 1\n",
        "            else:\n",
        "                falsos[j] += 1\n",
        "\n",
        "    for j in range(y_f.shape[1]):\n",
        "        # y_final.shape[1] -> 100%\n",
        "        # verdaderos[j]    -> X\n",
        "        verdaderos[j] = int(verdaderos[j] * 100 / y_f.shape[0])\n",
        "        falsos[j] = int(falsos[j] * 100 / y_f.shape[0])\n",
        "\n",
        "    return verdaderos, falsos, str(mean([v for i, v in verdaderos.items()])) + \"%\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UD-vRl8JCSMJ"
      },
      "outputs": [],
      "source": [
        "def preparar_datos_para_modelo(datos):\n",
        "    normalizador_pca = pickle.load(open(FOLDER_SAVE_NORMALIZADOR_PCA, 'rb'))\n",
        "    x_for_model = normalizador_pca.transform(X=datos)\n",
        "    return x_for_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAt-JZODb1EB"
      },
      "source": [
        "# 5.2. Cargando data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLvUo_8dCSGL",
        "outputId": "f8a9d962-ec8d-47c8-c3cb-518bfec5f772"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No se leeran los archivos de audios para convertirlos a numpy porque la opcion esta deshabilitada en la configuración\n"
          ]
        }
      ],
      "source": [
        "DATA, LABEL = None, None\n",
        "if EXTRACT_DATA_AUDIOS:\n",
        "    DATA, LABEL = files_to_data(TRAIN, \n",
        "                                buscar_todos_label=True, \n",
        "                                data_aumentation=FIND_DATA_INCREMENT)\n",
        "else:\n",
        "    print(\"No se leeran los archivos de audios para convertirlos a numpy porque la opcion esta deshabilitada en la configuración\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJZsVZ7dCSIK"
      },
      "outputs": [],
      "source": [
        "if EXTRACT_DATA_AUDIOS:\n",
        "    print(len(DATA), len(DATA[0]))\n",
        "    print(len(LABEL), len(LABEL[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz7vA6n_b7mX"
      },
      "source": [
        "# 5.3. Entrenando preprocesador de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOynOMeRCSKA"
      },
      "outputs": [],
      "source": [
        "if EXTRACT_DATA_AUDIOS:\n",
        "    # Normalizando y aplicando PCA\n",
        "    pca_pipe.fit(DATA)\n",
        "    pickle.dump(pca_pipe, open(FOLDER_SAVE_NORMALIZADOR_PCA,'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olMHYjQ-CSOD"
      },
      "outputs": [],
      "source": [
        "if EXTRACT_DATA_AUDIOS:\n",
        "    DATA_REDU = preparar_datos_para_modelo(DATA)\n",
        "    print(f\"Original vector size: {len(DATA[0])} -> New vector size {len(DATA_REDU[0])} ({int(MINIMA_VARIANA_EXPLICADA*100)}% información mantenida)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMJhslG2CSQN"
      },
      "outputs": [],
      "source": [
        "if EXTRACT_DATA_AUDIOS:\n",
        "    # Guardando datos\n",
        "    save_data(DATA_REDU, FOLDER_TRAIN_DATA)\n",
        "    save_data(LABEL, FOLDER_TRAIN_LABEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlCUeXKt10pE"
      },
      "outputs": [],
      "source": [
        "spark_data, DATA_REDU_df = read_data(FOLDER_TRAIN_DATA, to_numpy=True)\n",
        "spark_LABEL, LABEL_df = read_data(FOLDER_TRAIN_LABEL, to_numpy=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9ogBQ8E2YTr"
      },
      "outputs": [],
      "source": [
        "if EXTRACT_DATA_AUDIOS:\n",
        "    print(f\"Original vector size: {len(DATA[0])} -> New vector size {len(DATA_REDU_df[0])} ({int(MINIMA_VARIANA_EXPLICADA*100)}% información mantenida)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhkmsbTzcIiZ"
      },
      "source": [
        "# 5.4. Preparando data para train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVs5PeNSCSWo"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(DATA_REDU_df, LABEL_df, test_size=SPLIT_DATA_TRAIN)  # 0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmNVKoMgF685"
      },
      "source": [
        "# 6. Entrenando el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgWyNltQF1Ee",
        "outputId": "f6fae63a-58f2-4f5d-af34-8106426d4fcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo listo para entrenar\n"
          ]
        }
      ],
      "source": [
        "#@title Preparando el barrido del modelo para poder hacer GridSearchCV con RandomForestClassifier\n",
        "if REFIT:\n",
        "    import multiprocessing\n",
        "\n",
        "    params_grid = { \n",
        "        'n_estimators': [100, 150, 200, 700],\n",
        "        'max_features': ['auto', 'sqrt', 'log2'],\n",
        "        'max_depth': [None] + list(range(10, 50)),\n",
        "        'criterion': ['gini', 'entropy'],\n",
        "        'min_samples_split': [12, 16, 20]\n",
        "    }\n",
        "\n",
        "    rfc = RandomForestClassifier(n_jobs=-1,\n",
        "                                 max_features= 'sqrt' ,\n",
        "                                 n_estimators=50, \n",
        "                                 verbose=0,\n",
        "                                 oob_score = True) \n",
        "\n",
        "    seed = 1\n",
        "    grid = GridSearchCV(\n",
        "            estimator          = rfc,\n",
        "            param_grid         = params_grid,\n",
        "            scoring            = 'accuracy',\n",
        "            n_jobs             = multiprocessing.cpu_count() - 1,\n",
        "            cv                 = KFold(\n",
        "                n_splits=10, \n",
        "                shuffle=True, \n",
        "                random_state=seed),\n",
        "            refit              = True,\n",
        "            verbose            = 10,\n",
        "            return_train_score = True\n",
        "            )\n",
        "    \n",
        "    print(\"Modelo listo para entrenar\")\n",
        "\n",
        "    @count_elapsed_time\n",
        "    def train_model(grid_input):\n",
        "        print(\"Iniciando entrenamiento del modelo\")\n",
        "        grid_input.fit(X_train, y_train)\n",
        "        return grid_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "bWlJJCDv7DGw",
        "outputId": "c70ea370-5eee-4b55-b996-e57c8e1de433"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "function ClickConnect(){ \n",
              "    console.log(\"Clicked on star button\"); \n",
              "    document.querySelector(\"iron-icon#star-icon\").click() \n",
              "} \n",
              "setInterval(ClickConnect,10000)\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%html\n",
        "function ClickConnect(){ \n",
        "    console.log(\"Clicked on star button\"); \n",
        "    document.querySelector(\"iron-icon#star-icon\").click() \n",
        "} \n",
        "setInterval(ClickConnect,10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCHNwrZI8imv",
        "outputId": "d08819b2-abf2-4d08-da0a-1972ab36987e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando entrenamiento del modelo\n"
          ]
        }
      ],
      "source": [
        "if REFIT:\n",
        "    #@title Entrenando\n",
        "    grid = train_model(grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDgtXl2FR0Lq"
      },
      "outputs": [],
      "source": [
        "if REFIT:\n",
        "    resultados = pd.DataFrame(grid.cv_results_)\n",
        "    resultados.filter(regex = '(param*|mean_t|std_t)') \\\n",
        "        .drop(columns = 'params') \\\n",
        "        .sort_values('mean_test_score', ascending = False) \\\n",
        "        .head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBbyL6SgSEBK"
      },
      "outputs": [],
      "source": [
        "if REFIT:\n",
        "    # Mejores hiperparámetros por validación cruzada\n",
        "    # ==============================================================================\n",
        "    print(\"----------------------------------------\")\n",
        "    print(\"Mejores hiperparámetros encontrados (cv)\")\n",
        "    print(\"----------------------------------------\")\n",
        "    print(grid.best_params_, \":\", grid.best_score_, grid.scoring)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnfAY-uFF1Go"
      },
      "outputs": [],
      "source": [
        "if REFIT:\n",
        "    # Guardando el modelo\n",
        "    model = grid.best_estimator_\n",
        "    pickle.dump(model, open(FOLDER_MODEL, 'wb'))\n",
        "else:\n",
        "    # Cargando el modelo guardado\n",
        "    model = pickle.load(open(FOLDER_MODEL, 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE07Tl9oF_JK"
      },
      "outputs": [],
      "source": [
        "y_final = model.predict(X_valid)\n",
        "\n",
        "matrix_confusion_personalizada = calcular_porcentajes_aciertos(y_final, LABEL)[2]\n",
        "print(\"matrix_confusion_personalizada:\", matrix_confusion_personalizada)\n",
        "\n",
        "print(\"ACC\", metrics.accuracy_score(y_valid, y_final))\n",
        "print(\"PREC\", metrics.precision_score(y_valid, y_final, average='micro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNy5jawhSYjb"
      },
      "outputs": [],
      "source": [
        "predicciones = model.predict_proba(X = X_valid)\n",
        "predicciones[:5, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mb2eZERqGLLr"
      },
      "source": [
        "# 7. Testear el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlGNUZKpF_PX"
      },
      "outputs": [],
      "source": [
        "# Leyendo datos de testeo y calculando vector de caracteristicas\n",
        "if not os.path.exists(FOLDER_OUT + \"new_data/\"):\n",
        "    os.makedirs(FOLDER_OUT + \"new_data/\")\n",
        "\n",
        "DATA, LABEL = files_to_data(TEST, save_new_data=str(FOLDER_OUT + \"new_data/\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhZOkmZTF_Rm"
      },
      "outputs": [],
      "source": [
        "DATA_REDU = preparar_datos_para_modelo(DATA)\n",
        "\n",
        "print(f\"Original vector size: {len(DATA[0])} -> New vector size {len(DATA_REDU[0])} ({int(MINIMA_VARIANA_EXPLICADA*100)}% información mantenida)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKYX8L2tF_Ty"
      },
      "outputs": [],
      "source": [
        "# Guardando datos\n",
        "save_data(DATA_REDU, FOLDER_TEST_DATA)\n",
        "save_data(LABEL, FOLDER_TEST_LABEL)\n",
        "\n",
        "DATA_REDU = read_data(FOLDER_TEST_DATA)\n",
        "LABEL = read_data(FOLDER_TEST_LABEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-VYzfDbF_WI"
      },
      "outputs": [],
      "source": [
        "y_final = model.predict(DATA_REDU)\n",
        "\n",
        "matrix_confusion_personalizada = calcular_porcentajes_aciertos(y_final, LABEL)[2]\n",
        "print(\"matrix_confusion_personalizada:\", matrix_confusion_personalizada)\n",
        "\n",
        "print(\"ACC\", metrics.accuracy_score(LABEL, y_final))\n",
        "print(\"PREC\", metrics.precision_score(LABEL, y_final, average='micro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_E4HXykGWta"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsXHts6_GWxY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1D6H93EGWzw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOBu6XI1GW1q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glnVmQsyW09a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP8wJx+2LRUiT4eQd0XMZCC",
      "collapsed_sections": [
        "oWn-7Bgt11dz"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
