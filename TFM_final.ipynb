{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# librerias personalizadas\n",
    "from libraries.Corte_audio import Corte_audio\n",
    "from libraries.ProcessAudio import ProcessAudio\n",
    "\n",
    "# preprocesando los datos\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# para guardar el preprocesador de datos\n",
    "import pickle\n",
    "\n",
    "# Modelado\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Evaluacion\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# quitar alertas innecesarias\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "FOLDER_OUT = \"/kaggle/output/working/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "\n",
    "MINIMA_VARIANA_EXPLICADA = 0.93 # se debe definir porque este valor\n",
    "TIME_SPLIT = 2 # falta definir porque este split de 2\n",
    "\n",
    "# Folder\n",
    "FOLDER_SAVE_NORMALIZADOR_PCA = FOLDER_OUT + 'normalizador_pca.pkl'\n",
    "FOLDER_MODEL = FOLDER_OUT + \"randomforest.pkl\"\n",
    "\n",
    "FOLDER_TRAIN_DATA = FOLDER_OUT + \"train_data.csv\"\n",
    "FOLDER_TRAIN_LABEL = FOLDER_OUT + \"train_label.csv\"\n",
    "FOLDER_TEST_DATA = FOLDER_OUT + \"test_data.csv\"\n",
    "FOLDER_TEST_LABEL = FOLDER_OUT + \"test_label.csv\"\n",
    "\n",
    "# Model\n",
    "SPLIT_DATA_TRAIN = 0.2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "# iniciador de clases\n",
    "\n",
    "cortador = Corte_audio()\n",
    "pca_pipe = make_pipeline(StandardScaler(), PCA(MINIMA_VARIANA_EXPLICADA))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "# organizando los datos en train y test (data y label para cada uno)\n",
    "\n",
    "TRAIN = {}\n",
    "TEST = {}\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        file = os.path.join(dirname, filename)\n",
    "        name_file, extension = filename.split(\".\")\n",
    "\n",
    "        if extension == \"csv\" or extension == \"wav\":\n",
    "            if dirname.find(\"train\")>0:\n",
    "                if name_file not in TRAIN:\n",
    "                    TRAIN[name_file] = {}\n",
    "                if filename.find(\"csv\")>0:\n",
    "                    TRAIN[name_file]['label'] = file\n",
    "                else:\n",
    "                    TRAIN[name_file]['data'] = file\n",
    "            else:\n",
    "                if name_file not in TEST:\n",
    "                    TEST[name_file] = {}\n",
    "                if filename.find(\"csv\")>0:\n",
    "                    TEST[name_file]['label'] = file\n",
    "                else:\n",
    "                    TEST[name_file]['data'] = file\n",
    "\n",
    "# print(TRAIN)\n",
    "# print()\n",
    "# print(TEST)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# Abriendo cada audio, a cada uno se le aplica el split y a cada audio resultante se le extraen caracteristicas\n",
    "\n",
    "TODOS_LABEL = {}\n",
    "\n",
    "\n",
    "def files_to_data(diccionario_datos, buscar_todos_label: bool = False, save_new_data: bool = False):\n",
    "    global TODOS_LABEL\n",
    "    DATA = []\n",
    "    LABEL = []\n",
    "\n",
    "    for name_file, value in diccionario_datos.items():\n",
    "        print(name_file)\n",
    "        muestras_wav, instrumentos, rate = cortador.split_data(value['data'], value['label'])\n",
    "\n",
    "        processAudio = ProcessAudio(rate)\n",
    "        for id_audio, dat in enumerate(muestras_wav):\n",
    "            processAudio.set_data(dat)\n",
    "            caracteristicas = processAudio.get_all(id_audio)  # Extrayendo caracteristicas audios, salen 26 caracteristicas\n",
    "            DATA.append(caracteristicas[1:])\n",
    "            LABEL.append(instrumentos[id_audio])\n",
    "\n",
    "    # buscando todos los label\n",
    "    if buscar_todos_label:\n",
    "        for lab in LABEL:\n",
    "            for la in lab:\n",
    "                if la not in TODOS_LABEL:\n",
    "                    TODOS_LABEL[la] = 0\n",
    "        TODOS_LABEL = tuple(sorted(TODOS_LABEL))\n",
    "\n",
    "    # expandiendo los label a su respectivo vector de etiquetas\n",
    "    for j, lab in enumerate(LABEL):\n",
    "        new_label = [0 for _ in TODOS_LABEL]\n",
    "        for la in lab:\n",
    "            for i, l in enumerate(TODOS_LABEL):\n",
    "                if l == la:\n",
    "                    new_label[i] = 1\n",
    "        LABEL[j] = new_label\n",
    "\n",
    "    if save_new_data:\n",
    "        pass\n",
    "\n",
    "    # convirtiendo a numpy los datos\n",
    "    DATA = np.array(DATA, dtype=float)\n",
    "    LABEL = np.array(LABEL, dtype=float)\n",
    "\n",
    "    return DATA, LABEL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "def save_data(data_save, file):\n",
    "    df = pd.DataFrame(data=data_save)\n",
    "    df.to_csv(file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1733\n",
      "414 414\n"
     ]
    }
   ],
   "source": [
    "DATA, LABEL = files_to_data(TRAIN, buscar_todos_label=True)\n",
    "\n",
    "print(len(DATA), len(LABEL))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "# Normalizando y aplicando PCA\n",
    "pca_pipe.fit(DATA)\n",
    "pickle.dump(pca_pipe, open(FOLDER_SAVE_NORMALIZADOR_PCA,'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "normalizador_pca = pickle.load(open(FOLDER_SAVE_NORMALIZADOR_PCA, 'rb'))\n",
    "x_for_model = normalizador_pca.transform(X=DATA)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vector size: 26 -> New vector size 12 (93% información mantenida)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original vector size: {len(DATA[0])} -> New vector size {len(x_for_model[0])} ({int(MINIMA_VARIANA_EXPLICADA*100)}% información mantenida)\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "# Guardando datos\n",
    "save_data(DATA, FOLDER_TRAIN_DATA)\n",
    "save_data(LABEL, FOLDER_TRAIN_LABEL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "mean = lambda lst: int((sum(lst) / len(lst)) * 100) / 100\n",
    "\n",
    "def calcular_porcentajes_aciertos(y_f, y_t):\n",
    "    verdaderos = dict()\n",
    "    falsos = dict()\n",
    "    for j in range(y_f.shape[1]):\n",
    "        verdaderos[j] = 0\n",
    "        falsos[j] = 0\n",
    "\n",
    "    for i in range(y_f.shape[0]):\n",
    "        for j in range(y_f.shape[1]):\n",
    "            if y_f[i][j] == y_t[i][j]:\n",
    "                verdaderos[j] += 1\n",
    "            else:\n",
    "                falsos[j] += 1\n",
    "\n",
    "    for j in range(y_f.shape[1]):\n",
    "        # y_final.shape[1] -> 100%\n",
    "        # verdaderos[j]    -> X\n",
    "        verdaderos[j] = int(verdaderos[j] * 100 / y_f.shape[0])\n",
    "        falsos[j] = int(falsos[j] * 100 / y_f.shape[0])\n",
    "\n",
    "    return verdaderos, falsos, str(mean([v for i, v in verdaderos.items()])) + \"%\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "seed = 1\n",
    "grid = GridSearchCV(\n",
    "          estimator = RandomForestClassifier(),\n",
    "          param_grid={},\n",
    "          cv = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(DATA, LABEL, test_size=0.1)  # 0.2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "# Entrenando\n",
    "grid.fit(X_train, y_train)\n",
    "model = grid.best_estimator_\n",
    "pickle.dump(model, open(FOLDER_MODEL, 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 0.8333333333333334\n",
      "PREC 0.9341317365269461\n"
     ]
    }
   ],
   "source": [
    "y_final = model.predict(X_valid)\n",
    "print(\"ACC\", metrics.accuracy_score(y_valid, y_final))\n",
    "print(\"PREC\", metrics.precision_score(y_valid, y_final, average='micro'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1759\n",
      "1819\n",
      "2106\n"
     ]
    }
   ],
   "source": [
    "# TESTEAR EL MODELO\n",
    "model = pickle.load(open(FOLDER_MODEL, 'rb'))\n",
    "\n",
    "DATA, LABEL = files_to_data(TEST)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "# Guardando datos\n",
    "save_data(DATA, FOLDER_TEST_DATA)\n",
    "save_data(LABEL, FOLDER_TEST_LABEL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 0.33884297520661155\n",
      "PREC 0.4053156146179402\n"
     ]
    }
   ],
   "source": [
    "y_final = model.predict(DATA)\n",
    "print(\"ACC\", metrics.accuracy_score(LABEL, y_final))\n",
    "print(\"PREC\", metrics.precision_score(LABEL, y_final, average='micro'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}