{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 417,
   "outputs": [],
   "source": [
    "# ejecucion\n",
    "proyecto_en = \"PC\"  # kaggle - PC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "outputs": [],
   "source": [
    "def get_folder_out(project):\n",
    "    if project == \"kaggle\":\n",
    "        return \"/kaggle/output/working/\"\n",
    "    if project == \"PC\":\n",
    "        return os.sep.join(os.getcwd().split(os.sep)[:-1]) + os.sep + 'kaggle/output/working/'\n",
    "\n",
    "def get_folder_int(project):\n",
    "    if project == \"kaggle\":\n",
    "        return \"/kaggle/input\"\n",
    "    if project == \"PC\":\n",
    "        return os.sep.join(os.getcwd().split(os.sep)[:-1]) + os.sep + 'kaggle/input/musicnet-dataset'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "outputs": [],
   "source": [
    "FOLDER_OUT = get_folder_out(proyecto_en) # kaggle - PC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "\n",
    "MINIMA_VARIANA_EXPLICADA = 0.93 # se debe definir porque este valor\n",
    "TIME_SPLIT = 1 # falta definir porque este split de 2\n",
    "\n",
    "# Folder\n",
    "FOLDER_SAVE_NORMALIZADOR_PCA = FOLDER_OUT + 'normalizador_pca.pkl'\n",
    "FOLDER_MODEL = FOLDER_OUT + \"randomforest.pkl\"\n",
    "\n",
    "FOLDER_TRAIN_DATA = FOLDER_OUT + \"train_data.csv\"\n",
    "FOLDER_TRAIN_LABEL = FOLDER_OUT + \"train_label.csv\"\n",
    "FOLDER_TEST_DATA = FOLDER_OUT + \"test_data.csv\"\n",
    "FOLDER_TEST_LABEL = FOLDER_OUT + \"test_label.csv\"\n",
    "\n",
    "FOLDER_TAGS_LABEL = FOLDER_OUT + \"tags_label.csv\"\n",
    "# Model\n",
    "SPLIT_DATA_TRAIN = 0.2\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "outputs": [],
   "source": [
    "import os\n",
    "from distutils.version import StrictVersion\n",
    "\n",
    "# preprocesando los datos\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# para guardar el preprocesador de datos\n",
    "import pickle\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "# Modelado\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Evaluacion\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# quitar alertas innecesarias\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "outputs": [],
   "source": [
    "# librerias personalizadas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wav\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Corte_audio():\n",
    "    SEGUNDOS_CORTE = 5\n",
    "\n",
    "    def __init__(self, config_time: int = 5, save_audios: str = None):\n",
    "        self.SEGUNDOS_CORTE = config_time\n",
    "        self.save_audios = save_audios\n",
    "\n",
    "    def __hallar_instrumentos(self, corte_start, corte_end, instrument, start_time):\n",
    "        acumulador = list()\n",
    "        for (i, time_start) in enumerate(start_time):\n",
    "            if corte_end >= start_time[i] >= corte_start:\n",
    "                # print(start_time[i], end_time[i], instrument[i])\n",
    "                if not instrument[i] in acumulador:\n",
    "                    acumulador.append(instrument[i])\n",
    "            else:\n",
    "                if time_start > corte_end:\n",
    "                    break\n",
    "        return acumulador\n",
    "\n",
    "    def ___save_data(self, data_save, file):\n",
    "        df = pd.DataFrame(data=data_save, columns=['instrument'], index=None, dtype=None, copy=False)\n",
    "        df.to_csv(file, index=False)\n",
    "\n",
    "    def split_data(self, path_wav: str = \"\", path_csv: str = \"\", tag: str = \"dat\"):\n",
    "        (rate, sig) = wav.read(path_wav)\n",
    "        labels = pd.read_csv(path_csv)\n",
    "\n",
    "        instrument = labels['instrument']\n",
    "        start_time = labels['start_time']\n",
    "\n",
    "        pivote = 0\n",
    "        corte = rate * self.SEGUNDOS_CORTE\n",
    "\n",
    "        muestras = list()\n",
    "        instrumentos = list()\n",
    "        for _ in range(round(len(sig) / corte)):\n",
    "            corte_start, corte_end = pivote, pivote + corte\n",
    "            data = sig[corte_start:corte_end]\n",
    "            muestras.append(data)\n",
    "            instrumentos.append(self.__hallar_instrumentos(corte_start, corte_end, instrument, start_time))\n",
    "            pivote += corte\n",
    "\n",
    "        if pivote < len(sig):\n",
    "            data = sig[pivote:]\n",
    "            muestras.append(data)\n",
    "            instrumentos.append(self.__hallar_instrumentos(pivote, len(sig), instrument, start_time))\n",
    "\n",
    "        if self.save_audios is not None:\n",
    "            for i, data in enumerate(muestras):\n",
    "                wav.write(self.save_audios + f\"{tag}_{i}.wav\", rate, data)\n",
    "                self.___save_data(instrumentos[i], self.save_audios + f\"{tag}_{i}.csv\")\n",
    "\n",
    "        return muestras, instrumentos, rate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current vers 0.9.2\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "vers_required = \"0.7.2\"\n",
    "if StrictVersion(librosa.__version__) < StrictVersion(vers_required):\n",
    "    print(\"Error: minimum librosa vers: {}, current vers {}\".format(vers_required, librosa.__version__))\n",
    "    !pip install librosa===0.7.2 --force-reinstall\n",
    "\n",
    "print(\"current vers\", librosa.__version__)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "\n",
    "class ProcessAudio(object):\n",
    "    data = None\n",
    "\n",
    "    def __init__(self, sr:int = 44100):\n",
    "        self.mfcc = None\n",
    "        self.zcr = None\n",
    "        self.rolloff = None\n",
    "        self.spec_bw = None\n",
    "        self.spec_cent = None\n",
    "        self.rmse = None\n",
    "        self.chroma_stft = None\n",
    "        self.sr = sr\n",
    "\n",
    "    def set_data(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def display_waveform(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        # display waveform\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        librosa.display.waveplot(self.data , sr=self.sr)\n",
    "\n",
    "    def get_croma(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        self.chroma_stft = librosa.feature.chroma_stft(y=self.data, sr=self.sr)\n",
    "        return self.chroma_stft\n",
    "\n",
    "    def get_rmse(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        self.rmse = librosa.feature.rms(y=self.data)\n",
    "        return self.rmse\n",
    "\n",
    "    def get_centroide_espectral(self):\n",
    "        \"\"\"centroide espectral\"\"\"\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        self.spec_cent = librosa.feature.spectral_centroid(y=self.data, sr=self.sr)\n",
    "        return self.spec_cent\n",
    "\n",
    "    def get_ancho_banda_espectral(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        self.spec_bw = librosa.feature.spectral_bandwidth(y=self.data, sr=self.sr)\n",
    "        return self.spec_bw\n",
    "\n",
    "    def get_rolloff(self):\n",
    "        \"\"\"tambien conocido como reduccion espectral\"\"\"\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        self.rolloff = librosa.feature.spectral_rolloff(y=self.data, sr=self.sr)\n",
    "        return self.rolloff\n",
    "\n",
    "    def get_cruce_por_cero(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        self.zcr = librosa.feature.zero_crossing_rate(self.data)\n",
    "        return self.zcr\n",
    "\n",
    "    def get_mfcc(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        self.mfcc = librosa.feature.mfcc(y=self.data, sr=self.sr)\n",
    "        return self.mfcc\n",
    "\n",
    "    def get_all(self, i:int) -> list:\n",
    "        if self.data is None:\n",
    "            return []\n",
    "\n",
    "        self.get_croma()\n",
    "        self.get_rmse()\n",
    "        self.get_centroide_espectral()\n",
    "        self.get_ancho_banda_espectral()\n",
    "        self.get_rolloff()\n",
    "        self.get_cruce_por_cero()\n",
    "        self.get_mfcc()\n",
    "\n",
    "        data_compresed = f'train{i} {np.mean(self.chroma_stft)} {np.mean(self.rmse)} {np.mean(self.spec_cent)} {np.mean(self.spec_bw)} {np.mean(self.rolloff)} {np.mean(self.zcr)}'\n",
    "        for e in self.mfcc:\n",
    "            data_compresed += f' {np.mean(e)}'\n",
    "\n",
    "        return data_compresed.split()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.audio as naa\n",
    "import librosa.display as librosa_display\n",
    "\n",
    "\n",
    "class AudioAugmentation:\n",
    "    graph: bool = False\n",
    "    print_middleware: bool = False\n",
    "\n",
    "    def __init__(self, audio_file, graph=False, save: str = None):\n",
    "        self.audio_file = audio_file\n",
    "        self.graph = graph\n",
    "        self.save = save\n",
    "        if isinstance(audio_file, str):\n",
    "            print(\"Cargando archivo de audio\")\n",
    "            self.name_file = audio_file.split(\".\")[-2].split(\"/\")[-1]\n",
    "            self.data, self.rate = self.__read_audio_file(self.audio_file)\n",
    "        elif isinstance(audio_file, tuple):\n",
    "            #print(\"Audio file is a tuple\")\n",
    "            self.data, self.rate, self.name_file = audio_file\n",
    "            #print(len(self.data), self.rate, self.name_file)\n",
    "\n",
    "    def middleware_in(atributo1: str = \"\", ):\n",
    "        def _middleware_in(f):\n",
    "            def wrapper(self, *args, **kwargs):\n",
    "                # ejecucion antes de ejecutar la funcion\n",
    "                if self.print_middleware:\n",
    "                    print(f\"Middleware in {f.__name__} ({atributo1})\")\n",
    "\n",
    "                # ejecucion de la funcion\n",
    "                ejecucion_ok = True\n",
    "                try:\n",
    "                    salida = f(self, *args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    ejecucion_ok = False\n",
    "                    salida = e\n",
    "                    print(f\"Error en la ejecucion de la funcion {f.__name__}: {e}\")\n",
    "\n",
    "                # ejecucion despues de ejecutar la funcion\n",
    "                if ejecucion_ok:\n",
    "                    if self.graph:\n",
    "                        self.plot_audio(salida)\n",
    "\n",
    "                    if self.save is not None:\n",
    "                        try:\n",
    "                            if isinstance(salida, list):\n",
    "                                if self.print_middleware:\n",
    "                                    print(salida)\n",
    "                                salida = np.array(salida)\n",
    "                            self.write_audio_file(self.save + self.name_file + \"_\" + f\"{f.__name__}.wav\", salida, self.rate)\n",
    "                        except Exception as e:\n",
    "                            if self.print_middleware:\n",
    "                                print(f\"Error al guardar el archivo: {e}\")\n",
    "                            print(type(salida))\n",
    "\n",
    "                return salida\n",
    "\n",
    "            return wrapper\n",
    "\n",
    "        return _middleware_in\n",
    "\n",
    "    def plot_audio(self, data2=None):\n",
    "        librosa_display.waveshow(self.data, sr=self.rate, alpha=0.5)\n",
    "        if data2 is not None:\n",
    "            librosa_display.waveshow(data2, sr=self.rate, color='r', alpha=0.25)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    @middleware_in(atributo1=\"loudness_f\")\n",
    "    def loudness(self):\n",
    "        aug = naa.LoudnessAug()\n",
    "        augmented_data = aug.augment(self.data)[0]\n",
    "        return augmented_data\n",
    "\n",
    "    @middleware_in(atributo1=\"mask_f\")\n",
    "    def add_mask(self):\n",
    "        aug = naa.MaskAug(sampling_rate=self.rate, mask_with_noise=False)\n",
    "        augmented_data = aug.augment(self.data)[0]\n",
    "        return augmented_data\n",
    "\n",
    "    @middleware_in(atributo1=\"pitch_f\")\n",
    "    def pitch(self, fact=(2,3)):\n",
    "        aug = naa.PitchAug(sampling_rate=self.rate, factor=fact)\n",
    "        augmented_data = aug.augment(self.data)[0]\n",
    "        return augmented_data\n",
    "\n",
    "    @middleware_in(atributo1=\"original\")\n",
    "    def get_original(self):\n",
    "        return self.data\n",
    "\n",
    "    @middleware_in(atributo1=\"crop\")\n",
    "    def add_crop(self, porcentaje: float = 0.5):\n",
    "        crop = naa.CropAug(sampling_rate=self.rate)\n",
    "        augmented_data = crop.augment(self.data)[0]\n",
    "        return augmented_data\n",
    "\n",
    "    @staticmethod\n",
    "    def __read_audio_file(file_path):\n",
    "        input_length = 16000\n",
    "        data, rate = librosa.core.load(file_path)\n",
    "        if len(data) > input_length:\n",
    "            data = data[:input_length]\n",
    "        else:\n",
    "            data = np.pad(data, (0, max(0, input_length - len(data))), \"constant\")\n",
    "        return data, rate\n",
    "\n",
    "    @staticmethod\n",
    "    def write_audio_file(file, data, sample_rate):\n",
    "        write(file, sample_rate, data)\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_time_series(data):\n",
    "        fig = plt.figure(figsize=(14, 8))\n",
    "        plt.title('Raw wave ')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.plot(np.linspace(0, 1, len(data)), data)\n",
    "        plt.show()\n",
    "\n",
    "    @middleware_in(atributo1=\"ruido\")\n",
    "    def add_noise(self, factor_ruido=0.005):\n",
    "        noise = np.random.randn(len(self.data))\n",
    "        data_noise = self.data + factor_ruido * noise\n",
    "        data_noise = data_noise.astype(type(self.data[0]))  # Cast back to same\n",
    "        return data_noise\n",
    "\n",
    "    @middleware_in(atributo1=\"ruido2\")\n",
    "    def add_noise2(self):\n",
    "        aug = naa.NoiseAug()\n",
    "        augmented_data = aug.augment(self.data)[0]\n",
    "        return augmented_data\n",
    "\n",
    "    @middleware_in(atributo1=\"shift\")\n",
    "    def shift(self):\n",
    "        return np.roll(self.data, 1600)\n",
    "\n",
    "    @middleware_in(atributo1=\"stretch\")\n",
    "    def stretch(self, rate_stretch=1.0):\n",
    "        input_length = 16000\n",
    "        data = librosa.effects.time_stretch(self.data, rate=rate_stretch)\n",
    "        if len(data) > input_length:\n",
    "            data = data[:input_length]\n",
    "        else:\n",
    "            data = np.pad(data, (0, max(0, input_length - len(data))), \"constant\")\n",
    "        return data\n",
    "\n",
    "    @middleware_in(atributo1=\"speed\")\n",
    "    def speed(self):\n",
    "        aug = naa.SpeedAug()\n",
    "        augmented_data = aug.augment(self.data)[0]\n",
    "        return augmented_data\n",
    "\n",
    "    @middleware_in(atributo1=\"normalizador\")\n",
    "    def normalizer(self):\n",
    "        aug = naa.NormalizeAug(method='minmax')\n",
    "        augmented_data = aug.augment(self.data)[0]\n",
    "        return augmented_data\n",
    "\n",
    "    @middleware_in(atributo1=\"polarizador\")\n",
    "    def polarizer(self):\n",
    "        aug = naa.PolarityInverseAug()\n",
    "        augmented_data = aug.augment(self.data)[0]\n",
    "        return augmented_data\n",
    "\n",
    "\n",
    "class Audio_K(AudioAugmentation):\n",
    "\n",
    "    def __init__(self, file_path, label: list, save: str = None, grafica: bool = False):\n",
    "        super().__init__(file_path, save=save, graph=grafica)\n",
    "        self.label = label\n",
    "\n",
    "    def aumentar(self):\n",
    "        all_data = [\n",
    "            self.get_original(),\n",
    "            self.add_noise(factor_ruido=0.05),\n",
    "            self.add_noise2(),\n",
    "            self.stretch(rate_stretch=0.8),\n",
    "            self.shift(),\n",
    "            self.add_crop(),\n",
    "            self.loudness(),\n",
    "            self.speed(),\n",
    "            self.normalizer(),\n",
    "            self.polarizer()\n",
    "        ]\n",
    "\n",
    "        all_label = [self.label for _ in range(len(all_data))]\n",
    "        return all_data, all_label\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "from time import time\n",
    "\n",
    "\n",
    "def count_elapsed_time(f):\n",
    "    @wraps(f)\n",
    "    def cronometro(*args, **kwargs):\n",
    "        t_inicial = time()  # tomo la hora antes de ejecutar la funcion\n",
    "        salida = f(*args, **kwargs)\n",
    "        t_final = time()  # tomo la hora despues de ejecutar la funcion\n",
    "        print('Tiempo transcurrido (en segundos): {}'.format(t_final - t_inicial))\n",
    "        return salida\n",
    "\n",
    "    return cronometro"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iniciador de clases\n",
    "\n",
    "pca_pipe = make_pipeline(StandardScaler(), PCA(MINIMA_VARIANA_EXPLICADA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo transcurrido (en segundos): 0.009542226791381836\n"
     ]
    }
   ],
   "source": [
    "# organizando los datos en train y test (data y label para cada uno)\n",
    "\n",
    "TRAIN = {}\n",
    "TEST = {}\n",
    "\n",
    "@count_elapsed_time\n",
    "def crear_diccionarios_train_test():\n",
    "    for dirname, _, filenames in os.walk(get_folder_int(proyecto_en)):\n",
    "        for filename in filenames:\n",
    "            file = os.path.join(dirname, filename)\n",
    "            name_file, extension = filename.split(\".\")\n",
    "\n",
    "            if extension == \"csv\" or extension == \"wav\":\n",
    "                if dirname.find(\"train\")>0:\n",
    "                    if name_file not in TRAIN:\n",
    "                        TRAIN[name_file] = {}\n",
    "                    if filename.find(\"csv\")>0:\n",
    "                        TRAIN[name_file]['label'] = file\n",
    "                    else:\n",
    "                        TRAIN[name_file]['data'] = file\n",
    "                else:\n",
    "                    if name_file not in TEST:\n",
    "                        TEST[name_file] = {}\n",
    "                    if filename.find(\"csv\")>0:\n",
    "                        TEST[name_file]['label'] = file\n",
    "                    else:\n",
    "                        TEST[name_file]['data'] = file\n",
    "crear_diccionarios_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODOS_LABEL = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data_save, file):\n",
    "    df = pd.DataFrame(data=data_save)\n",
    "    df.to_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = lambda lst: int((sum(lst) / len(lst)) * 100) / 100\n",
    "\n",
    "def calcular_porcentajes_aciertos(y_f, y_t):\n",
    "    verdaderos = dict()\n",
    "    falsos = dict()\n",
    "    for j in range(y_f.shape[1]):\n",
    "        verdaderos[j] = 0\n",
    "        falsos[j] = 0\n",
    "\n",
    "    for i in range(y_f.shape[0]):\n",
    "        for j in range(y_f.shape[1]):\n",
    "            if y_f[i][j] == y_t[i][j]:\n",
    "                verdaderos[j] += 1\n",
    "            else:\n",
    "                falsos[j] += 1\n",
    "\n",
    "    for j in range(y_f.shape[1]):\n",
    "        # y_final.shape[1] -> 100%\n",
    "        # verdaderos[j]    -> X\n",
    "        verdaderos[j] = int(verdaderos[j] * 100 / y_f.shape[0])\n",
    "        falsos[j] = int(falsos[j] * 100 / y_f.shape[0])\n",
    "\n",
    "    return verdaderos, falsos, str(mean([v for i, v in verdaderos.items()])) + \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "outputs": [],
   "source": [
    "# Abriendo cada audio, a cada uno se le aplica el split y a cada audio resultante se le extraen caracteristicas\n",
    "\n",
    "\n",
    "@count_elapsed_time\n",
    "def files_to_data(diccionario_datos, buscar_todos_label: bool = False, save_new_data: str = None, data_aumentation: bool = False):\n",
    "    global TODOS_LABEL\n",
    "    conteo = 0\n",
    "\n",
    "    DATA = []\n",
    "    LABEL = []\n",
    "\n",
    "    rate = 0\n",
    "\n",
    "    cortador = Corte_audio(config_time=TIME_SPLIT, save_audios=save_new_data)\n",
    "\n",
    "    for name_file, value in diccionario_datos.items():\n",
    "        if 'data' in value and 'label' in value:\n",
    "            conteo += 1\n",
    "            print(name_file, end=\" - \")\n",
    "            if conteo >= 20:\n",
    "                print()\n",
    "                conteo = 0\n",
    "\n",
    "            muestras_wav, instrumentos, rate = cortador.split_data(value['data'], value['label'])\n",
    "\n",
    "            if data_aumentation and buscar_todos_label:\n",
    "                new_muestras = []\n",
    "                new_instruments = []\n",
    "                for id_audio, dat in enumerate(muestras_wav):\n",
    "                    data_audio_para_amplificar= (dat, rate, \"data_\" + str(id_audio))\n",
    "                    label_audio_para_amplificar = instrumentos[id_audio]\n",
    "                    data_amplificada, label_amplificada = Audio_K(data_audio_para_amplificar, label=label_audio_para_amplificar).aumentar()\n",
    "                    #print(len(data_amplificada))\n",
    "                    for id_new_audio, new_audio in enumerate(data_amplificada):\n",
    "                        new_data_add = new_audio\n",
    "                        new_label_add = label_amplificada[id_new_audio]\n",
    "\n",
    "                        ok = True\n",
    "                        try:\n",
    "                            cte = 110250\n",
    "                            if (TIME_SPLIT*rate) > len(new_data_add):\n",
    "                                new_data_add += [0 for _ in range(cte*TIME_SPLIT)]\n",
    "                            if (TIME_SPLIT*rate) < len(new_data_add):\n",
    "                                new_data_add = new_data_add[:TIME_SPLIT*cte]\n",
    "                        except Exception as e:\n",
    "                            ok = False\n",
    "\n",
    "                        if ok:\n",
    "                            new_muestras.append(new_data_add)\n",
    "                            new_instruments.append(new_label_add)\n",
    "\n",
    "                muestras_wav, instrumentos = new_muestras, new_instruments\n",
    "\n",
    "            processAudio = ProcessAudio(rate)\n",
    "            for id_audio, dat in enumerate(muestras_wav):\n",
    "                processAudio.set_data(dat)\n",
    "                # print(len(dat), end = \">\")\n",
    "                ok = True\n",
    "                caracteristicas = None\n",
    "                try:\n",
    "                    caracteristicas = processAudio.get_all(id_audio)  # Extrayendo caracteristicas audios, salen 26 caracteristicas\n",
    "                except:\n",
    "                    ok = False\n",
    "                if ok:\n",
    "                    DATA.append(caracteristicas[1:])\n",
    "                    LABEL.append(instrumentos[id_audio])\n",
    "\n",
    "    # buscando todos los label\n",
    "    if buscar_todos_label:\n",
    "        for lab in LABEL:\n",
    "            for la in lab:\n",
    "                if la not in TODOS_LABEL:\n",
    "                    TODOS_LABEL[la] = 0\n",
    "        TODOS_LABEL = tuple(sorted(TODOS_LABEL))\n",
    "\n",
    "    # expandiendo los label a su respectivo vector de etiquetas\n",
    "    for j, lab in enumerate(LABEL):\n",
    "        new_label = [0 for _ in TODOS_LABEL]\n",
    "        for la in lab:\n",
    "            for i, l in enumerate(TODOS_LABEL):\n",
    "                if l == la:\n",
    "                    new_label[i] = 1\n",
    "        LABEL[j] = new_label\n",
    "\n",
    "\n",
    "    # convirtiendo a numpy los datos\n",
    "    DATA = np.array(DATA, dtype=float)\n",
    "    LABEL = np.array(LABEL, dtype=float)\n",
    "\n",
    "    return DATA, LABEL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1727 - 1728 - 1729 - 1730 - 1733 - 1734 - 1735 - 1739 - 1742 - 1749 - 1750 - 1751 - 1752 - 1755 - 1756 - 1757 - 1758 - 1760 - 1763 - 1765 - \n",
      "1766 - 1768 - 1771 - 1772 - 1773 - 1775 - 1776 - 1777 - 1788 - 1789 - 1790 - 1791 - 1792 - 1793 - 1805 - 1807 - 1811 - 1812 - 1817 - 1818 - \n",
      "1822 - 1824 - 1828 - 1829 - 1835 - 1859 - 1872 - 1873 - 1876 - 1893 - 1916 - 1918 - 1919 - 1922 - 1923 - 1931 - 1932 - 2075 - 2076 - 2077 - \n",
      "2078 - 2079 - 2080 - 2081 - 2082 - 2083 - 2104 - 2105 - 2112 - 2113 - 2114 - 2116 - 2117 - 2118 - 2119 - 2127 - 2138 - 2140 - 2147 - 2148 - \n",
      "2149 - 2150 - 2151 - 2154 - 2155 - 2156 - 2157 - 2158 - 2159 - 2160 - 2161 - 2166 - 2167 - 2168 - 2169 - 1764 - 1813 - 1933 - 2131 - 2177 - \n",
      "2213 - 2239 - 2300 - 2342 - 2381 - 2422 - 2478 - 2510 - 2557 - 2594 - 2178 - 2179 - 2180 - 2186 - 2194 - 2195 - 2196 - 2198 - 2200 - 2201 - \n",
      "2202 - 2203 - 2204 - 2207 - 2208 - 2209 - 2210 - 2211 - 2212 - 2214 - 2215 - 2217 - 2218 - 2219 - 2220 - 2221 - 2222 - 2224 - 2225 - 2227 - \n",
      "2228 - 2229 - 2230 - 2231 - 2232 - 2234 - 2237 - 2238 - 2240 - 2241 - 2242 - 2243 - 2244 - 2247 - 2248 - 2282 - 2283 - 2284 - 2285 - 2288 - \n",
      "2289 - 2292 - 2293 - 2294 - 2295 - 2296 - 2297 - 2302 - 2304 - 2305 - 2307 - 2308 - 2310 - 2313 - 2314 - 2315 - 2318 - 2319 - 2320 - 2322 - \n",
      "2325 - 2330 - 2334 - 2335 - 2336 - 2341 - 2343 - 2345 - 2346 - 2348 - 2350 - 2357 - 2358 - 2359 - 2364 - 2365 - 2366 - 2368 - 2371 - 2372 - \n",
      "2373 - 2374 - 2376 - 2377 - 2379 - 2383 - 2384 - 2388 - 2389 - 2390 - 2391 - 2392 - 2393 - 2397 - 2398 - 2403 - 2404 - 2405 - 2406 - 2410 - \n",
      "2411 - 2415 - 2417 - 2420 - 2423 - 2424 - 2431 - 2432 - 2433 - 2436 - 2441 - 2442 - 2443 - 2444 - 2451 - 2462 - 2463 - 2466 - 2471 - 2472 - \n",
      "2473 - 2476 - 2477 - 2480 - 2481 - 2482 - 2483 - 2486 - 2487 - 2488 - 2490 - 2491 - 2492 - 2494 - 2497 - 2501 - 2502 - 2504 - 2505 - 2506 - \n",
      "2507 - 2509 - 2512 - 2514 - 2516 - 2521 - 2522 - 2523 - 2527 - 2528 - 2529 - 2530 - 2531 - 2532 - 2533 - 2537 - 2538 - 2540 - 2542 - 2550 - \n",
      "2555 - 2560 - 2562 - 2564 - 2566 - 2567 - 2568 - 2570 - 2571 - 2572 - 2573 - 2575 - 2576 - 2581 - 2582 - 2586 - 2588 - 2590 - 2591 - 2593 - \n",
      "2595 - 2596 - 2603 - 2607 - 2608 - 2611 - 2614 - 2618 - 2619 - 2620 - 2621 - 2622 - 2626 - 2627 - 2629 - 2632 - 2633 - 2659 - 2677 - 2678 - \n",
      "Tiempo transcurrido (en segundos): 39715.044018268585\n"
     ]
    }
   ],
   "source": [
    "DATA, LABEL = files_to_data(TRAIN, buscar_todos_label=True, data_aumentation=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888543 26\n",
      "888543 11\n"
     ]
    }
   ],
   "source": [
    "print(len(DATA), len(DATA[0]))\n",
    "print(len(LABEL), len(LABEL[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "outputs": [],
   "source": [
    "save_data([TODOS_LABEL], FOLDER_TAGS_LABEL)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "outputs": [],
   "source": [
    "# Normalizando y aplicando PCA\n",
    "pca_pipe.fit(DATA)\n",
    "pickle.dump(pca_pipe, open(FOLDER_SAVE_NORMALIZADOR_PCA,'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "outputs": [],
   "source": [
    "def preparar_datos_para_modelo(datos):\n",
    "    normalizador_pca = pickle.load(open(FOLDER_SAVE_NORMALIZADOR_PCA, 'rb'))\n",
    "    x_for_model = normalizador_pca.transform(X=datos)\n",
    "    return x_for_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "outputs": [],
   "source": [
    "DATA = preparar_datos_para_modelo(DATA)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vector size: 15 -> New vector size 15 (93% información mantenida)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original vector size: {len(DATA[0])} -> New vector size {len(DATA[0])} ({int(MINIMA_VARIANA_EXPLICADA*100)}% información mantenida)\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "outputs": [],
   "source": [
    "# Guardando datos\n",
    "save_data(DATA, FOLDER_TRAIN_DATA)\n",
    "save_data(LABEL, FOLDER_TRAIN_LABEL)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(DATA, LABEL, test_size=0.1)  # 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "outputs": [],
   "source": [
    "seed = 1\n",
    "grid = GridSearchCV(\n",
    "          estimator = RandomForestClassifier(),\n",
    "          param_grid={},\n",
    "          cv = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenando\n",
    "grid.fit(X_train, y_train)\n",
    "model = grid.best_estimator_\n",
    "pickle.dump(model, open(FOLDER_MODEL, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix_confusion_personalizada: 84.81%\n"
     ]
    }
   ],
   "source": [
    "matrix_confusion_personalizada = calcular_porcentajes_aciertos(y_final, LABEL)[2]\n",
    "print(\"matrix_confusion_personalizada:\", matrix_confusion_personalizada)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 0.8338979235833661\n",
      "PREC 0.9392451877376425\n"
     ]
    }
   ],
   "source": [
    "print(\"ACC\", metrics.accuracy_score(y_valid, y_final))\n",
    "print(\"PREC\", metrics.precision_score(y_valid, y_final, average='micro'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testear el modelo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "outputs": [],
   "source": [
    "# Cargando el modelo guardado\n",
    "model = pickle.load(open(FOLDER_MODEL, 'rb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1759 - 1819 - 2106 - 2191 - 2298 - 2303 - 2382 - 2416 - 2556 - 2628 - Tiempo transcurrido (en segundos): 66.27676653862\n"
     ]
    }
   ],
   "source": [
    "# Leyendo datos de testeo y calculando vector de caracteristicas\n",
    "if not os.path.exists(FOLDER_OUT + \"new_data/\"):\n",
    "    os.makedirs(FOLDER_OUT + \"new_data/\")\n",
    "\n",
    "DATA, LABEL = files_to_data(TEST, save_new_data=str(FOLDER_OUT + \"new_data/\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "outputs": [],
   "source": [
    "DATA_REDU = preparar_datos_para_modelo(DATA)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vector size: 26 -> New vector size 15 (93% información mantenida)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original vector size: {len(DATA[0])} -> New vector size {len(DATA_REDU[0])} ({int(MINIMA_VARIANA_EXPLICADA*100)}% información mantenida)\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardando datos\n",
    "save_data(DATA_REDU, FOLDER_TEST_DATA)\n",
    "save_data(LABEL, FOLDER_TEST_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final = model.predict(DATA_REDU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix_confusion_personalizada: 95.0%\n"
     ]
    }
   ],
   "source": [
    "matrix_confusion_personalizada = calcular_porcentajes_aciertos(y_final, LABEL)[2]\n",
    "print(\"matrix_confusion_personalizada:\", matrix_confusion_personalizada)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 0.705050505050505\n",
      "PREC 0.865924276169265\n"
     ]
    }
   ],
   "source": [
    "print(\"ACC\", metrics.accuracy_score(LABEL, y_final))\n",
    "print(\"PREC\", metrics.precision_score(LABEL, y_final, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testo unitario"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "outputs": [],
   "source": [
    "path_label_test_unit = FOLDER_OUT + \"new_data/dat_0.csv\"\n",
    "path_data_test_unit = FOLDER_OUT + \"new_data/dat_0.wav\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "outputs": [],
   "source": [
    "def expandir_tags_out(original_tag, all_tags):\n",
    "    LABEL = original_tag.get(\"instrument\").to_numpy()\n",
    "\n",
    "    # expandiendo los label al array de tags entrenado\n",
    "    new_label = [0 for _ in all_tags]\n",
    "    for la in LABEL:\n",
    "        for i, l in enumerate(all_tags):\n",
    "            if l == la:\n",
    "                new_label[i] = 1\n",
    "    LABEL = new_label\n",
    "    return LABEL\n",
    "\n",
    "@count_elapsed_time\n",
    "def predecir_archivo_unitario(data_wav, rate):\n",
    "    processAudio = ProcessAudio(rate)\n",
    "    processAudio.set_data(data_wav)\n",
    "    DATA = processAudio.get_all(\"0\")[1:]  # Extrayendo caracteristicas audios, salen 26 caracteristicas\n",
    "    DATA_REDU = preparar_datos_para_modelo([DATA])\n",
    "\n",
    "    # Cargando el modelo guardado\n",
    "    model = pickle.load(open(FOLDER_MODEL, 'rb'))\n",
    "    y_final = model.predict(DATA_REDU)\n",
    "\n",
    "    return y_final"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo transcurrido (en segundos): 71.18626976013184\n"
     ]
    }
   ],
   "source": [
    "(DATA, rate) = librosa.core.load(path_data_test_unit)\n",
    "\n",
    "y_final = predecir_archivo_unitario(DATA, rate)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix_confusion_personalizada: 90.9%\n",
      "ACC 0.0\n",
      "PREC 1.0\n"
     ]
    }
   ],
   "source": [
    "LABEL = pd.read_csv(path_label_test_unit, header=0)\n",
    "LABEL = expandir_tags_out(LABEL, TODOS_LABEL)\n",
    "\n",
    "matrix_confusion_personalizada = calcular_porcentajes_aciertos(y_final, [LABEL])[2]\n",
    "print(\"matrix_confusion_personalizada:\", matrix_confusion_personalizada)\n",
    "\n",
    "print(\"ACC\", metrics.accuracy_score([LABEL], y_final))\n",
    "print(\"PREC\", metrics.precision_score([LABEL], y_final, average='micro'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
