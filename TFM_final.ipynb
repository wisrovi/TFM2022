{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "# ejecucion\n",
    "proyecto_en = \"PC\"  # kaggle - PC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "def get_folder_out(project):\n",
    "    if project == \"kaggle\":\n",
    "        return \"/kaggle/output/working/\"\n",
    "    if project == \"PC\":\n",
    "        return os.sep.join(os.getcwd().split(os.sep)[:-1]) + os.sep + 'kaggle/output/working'\n",
    "\n",
    "def get_folder_int(project):\n",
    "    if project == \"kaggle\":\n",
    "        return \"/kaggle/input\"\n",
    "    if project == \"PC\":\n",
    "        return os.sep.join(os.getcwd().split(os.sep)[:-1]) + os.sep + 'kaggle/input/musicnet-dataset'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "FOLDER_OUT = get_folder_out(proyecto_en) # kaggle - PC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "\n",
    "MINIMA_VARIANA_EXPLICADA = 0.93 # se debe definir porque este valor\n",
    "TIME_SPLIT = 2 # falta definir porque este split de 2\n",
    "\n",
    "# Folder\n",
    "FOLDER_SAVE_NORMALIZADOR_PCA = FOLDER_OUT + 'normalizador_pca.pkl'\n",
    "FOLDER_MODEL = FOLDER_OUT + \"randomforest.pkl\"\n",
    "\n",
    "FOLDER_TRAIN_DATA = FOLDER_OUT + \"train_data.csv\"\n",
    "FOLDER_TRAIN_LABEL = FOLDER_OUT + \"train_label.csv\"\n",
    "FOLDER_TEST_DATA = FOLDER_OUT + \"test_data.csv\"\n",
    "FOLDER_TEST_LABEL = FOLDER_OUT + \"test_label.csv\"\n",
    "\n",
    "# Model\n",
    "SPLIT_DATA_TRAIN = 0.2\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "import os\n",
    "from distutils.version import StrictVersion\n",
    "\n",
    "# preprocesando los datos\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# para guardar el preprocesador de datos\n",
    "import pickle\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "# Modelado\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Evaluacion\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# quitar alertas innecesarias\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "# librerias personalizadas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wav\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Corte_audio():\n",
    "    SEGUNDOS_CORTE = 5\n",
    "\n",
    "    def __init__(self, config_time:int=5):\n",
    "        self.SEGUNDOS_CORTE = config_time\n",
    "\n",
    "    def __hallar_instrumentos(self, corte_start, corte_end, instrument, start_time):\n",
    "        acumulador = list()\n",
    "        for (i, time_start) in enumerate(start_time):\n",
    "            if corte_end >= start_time[i] >= corte_start:\n",
    "                # print(start_time[i], end_time[i], instrument[i])\n",
    "                if not instrument[i] in acumulador:\n",
    "                    acumulador.append(instrument[i])\n",
    "            else:\n",
    "                if time_start > corte_end:\n",
    "                    break\n",
    "        return acumulador\n",
    "\n",
    "    def split_data(self, path_wav:str= \"\", path_csv:str= \"\"):\n",
    "        (rate, sig) = wav.read(path_wav)\n",
    "        labels = pd.read_csv(path_csv)\n",
    "\n",
    "        instrument = labels['instrument']\n",
    "        start_time = labels['start_time']\n",
    "\n",
    "        pivote = 0\n",
    "        corte = rate * self.SEGUNDOS_CORTE\n",
    "\n",
    "        muestras = list()\n",
    "        instrumentos = list()\n",
    "        for _ in range(round(len(sig) / corte)):\n",
    "            corte_start, corte_end = pivote, pivote + corte\n",
    "            data = sig[corte_start:corte_end]\n",
    "            muestras.append(data)\n",
    "            instrumentos.append(self.__hallar_instrumentos(corte_start, corte_end, instrument, start_time))\n",
    "            pivote += corte\n",
    "\n",
    "        if pivote < len(sig):\n",
    "            data = sig[pivote:]\n",
    "            muestras.append(data)\n",
    "            instrumentos.append(self.__hallar_instrumentos(pivote, len(sig), instrument, start_time))\n",
    "\n",
    "        return muestras, instrumentos, rate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current vers 0.9.2\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "vers_required = \"0.7.2\"\n",
    "if StrictVersion(librosa.__version__) < StrictVersion(vers_required):\n",
    "    print(\"Error: minimum librosa vers: {}, current vers {}\".format(vers_required, librosa.__version__))\n",
    "    !pip install librosa===0.7.2 --force-reinstall\n",
    "\n",
    "print(\"current vers\", librosa.__version__)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "\n",
    "class ProcessAudio(object):\n",
    "    data = None\n",
    "\n",
    "    def __init__(self, sr:int = 44100):\n",
    "        self.mfcc = None\n",
    "        self.zcr = None\n",
    "        self.rolloff = None\n",
    "        self.spec_bw = None\n",
    "        self.spec_cent = None\n",
    "        self.rmse = None\n",
    "        self.chroma_stft = None\n",
    "        self.sr = sr\n",
    "\n",
    "    def set_data(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def display_waveform(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        # display waveform\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        librosa.display.waveplot(self.data , sr=self.sr)\n",
    "\n",
    "    def get_croma(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        self.chroma_stft = librosa.feature.chroma_stft(y=self.data, sr=self.sr)\n",
    "        return self.chroma_stft\n",
    "\n",
    "    def get_rmse(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        self.rmse = librosa.feature.rms(y=self.data)\n",
    "        return self.rmse\n",
    "\n",
    "    def get_centroide_espectral(self):\n",
    "        \"\"\"centroide espectral\"\"\"\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        self.spec_cent = librosa.feature.spectral_centroid(y=self.data, sr=self.sr)\n",
    "        return self.spec_cent\n",
    "\n",
    "    def get_ancho_banda_espectral(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        self.spec_bw = librosa.feature.spectral_bandwidth(y=self.data, sr=self.sr)\n",
    "        return self.spec_bw\n",
    "\n",
    "    def get_rolloff(self):\n",
    "        \"\"\"tambien conocido como reduccion espectral\"\"\"\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        self.rolloff = librosa.feature.spectral_rolloff(y=self.data, sr=self.sr)\n",
    "        return self.rolloff\n",
    "\n",
    "    def get_cruce_por_cero(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        self.zcr = librosa.feature.zero_crossing_rate(self.data)\n",
    "        return self.zcr\n",
    "\n",
    "    def get_mfcc(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        self.mfcc = librosa.feature.mfcc(y=self.data, sr=self.sr)\n",
    "        return self.mfcc\n",
    "\n",
    "    def get_all(self, i:int) -> list:\n",
    "        if self.data is None:\n",
    "            return []\n",
    "\n",
    "        self.get_croma()\n",
    "        self.get_rmse()\n",
    "        self.get_centroide_espectral()\n",
    "        self.get_ancho_banda_espectral()\n",
    "        self.get_rolloff()\n",
    "        self.get_cruce_por_cero()\n",
    "        self.get_mfcc()\n",
    "\n",
    "        data_compresed = f'train{i} {np.mean(self.chroma_stft)} {np.mean(self.rmse)} {np.mean(self.spec_cent)} {np.mean(self.spec_bw)} {np.mean(self.rolloff)} {np.mean(self.zcr)}'\n",
    "        for e in self.mfcc:\n",
    "            data_compresed += f' {np.mean(e)}'\n",
    "\n",
    "        return data_compresed.split()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "from time import time\n",
    "\n",
    "\n",
    "def count_elapsed_time(f):\n",
    "    @wraps(f)\n",
    "    def cronometro(*args, **kwargs):\n",
    "        t_inicial = time()  # tomo la hora antes de ejecutar la funcion\n",
    "        salida = f(*args, **kwargs)\n",
    "        t_final = time()  # tomo la hora despues de ejecutar la funcion\n",
    "        print('Tiempo transcurrido (en segundos): {}'.format(t_final - t_inicial))\n",
    "        return salida\n",
    "\n",
    "    return cronometro"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iniciador de clases\n",
    "\n",
    "cortador = Corte_audio()\n",
    "pca_pipe = make_pipeline(StandardScaler(), PCA(MINIMA_VARIANA_EXPLICADA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo transcurrido (en segundos): 0.014384746551513672\n"
     ]
    }
   ],
   "source": [
    "# organizando los datos en train y test (data y label para cada uno)\n",
    "\n",
    "TRAIN = {}\n",
    "TEST = {}\n",
    "\n",
    "@count_elapsed_time\n",
    "def crear_diccionarios_train_test():\n",
    "    for dirname, _, filenames in os.walk(get_folder_int(proyecto_en)):\n",
    "        for filename in filenames:\n",
    "            file = os.path.join(dirname, filename)\n",
    "            name_file, extension = filename.split(\".\")\n",
    "\n",
    "            if extension == \"csv\" or extension == \"wav\":\n",
    "                if dirname.find(\"train\")>0:\n",
    "                    if name_file not in TRAIN:\n",
    "                        TRAIN[name_file] = {}\n",
    "                    if filename.find(\"csv\")>0:\n",
    "                        TRAIN[name_file]['label'] = file\n",
    "                    else:\n",
    "                        TRAIN[name_file]['data'] = file\n",
    "                else:\n",
    "                    if name_file not in TEST:\n",
    "                        TEST[name_file] = {}\n",
    "                    if filename.find(\"csv\")>0:\n",
    "                        TEST[name_file]['label'] = file\n",
    "                    else:\n",
    "                        TEST[name_file]['data'] = file\n",
    "crear_diccionarios_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODOS_LABEL = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data_save, file):\n",
    "    df = pd.DataFrame(data=data_save)\n",
    "    df.to_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "# Abriendo cada audio, a cada uno se le aplica el split y a cada audio resultante se le extraen caracteristicas\n",
    "\n",
    "\n",
    "@count_elapsed_time\n",
    "def files_to_data(diccionario_datos, buscar_todos_label: bool = False, save_new_data: bool = False):\n",
    "    global TODOS_LABEL\n",
    "    conteo = 0\n",
    "\n",
    "    DATA = []\n",
    "    LABEL = []\n",
    "\n",
    "    rate = 0\n",
    "    for name_file, value in diccionario_datos.items():\n",
    "        conteo += 1\n",
    "        print(name_file, end=\" - \")\n",
    "        if conteo >= 10:\n",
    "            print()\n",
    "            conteo = 0\n",
    "\n",
    "        muestras_wav, instrumentos, rate = cortador.split_data(value['data'], value['label'])\n",
    "\n",
    "        processAudio = ProcessAudio(rate)\n",
    "        for id_audio, dat in enumerate(muestras_wav):\n",
    "            processAudio.set_data(dat)\n",
    "            caracteristicas = processAudio.get_all(id_audio)  # Extrayendo caracteristicas audios, salen 26 caracteristicas\n",
    "            DATA.append(caracteristicas[1:])\n",
    "            LABEL.append(instrumentos[id_audio])\n",
    "\n",
    "    # buscando todos los label\n",
    "    if buscar_todos_label:\n",
    "        for lab in LABEL:\n",
    "            for la in lab:\n",
    "                if la not in TODOS_LABEL:\n",
    "                    TODOS_LABEL[la] = 0\n",
    "        TODOS_LABEL = tuple(sorted(TODOS_LABEL))\n",
    "\n",
    "    # expandiendo los label a su respectivo vector de etiquetas\n",
    "    for j, lab in enumerate(LABEL):\n",
    "        new_label = [0 for _ in TODOS_LABEL]\n",
    "        for la in lab:\n",
    "            for i, l in enumerate(TODOS_LABEL):\n",
    "                if l == la:\n",
    "                    new_label[i] = 1\n",
    "        LABEL[j] = new_label\n",
    "\n",
    "    if save_new_data:\n",
    "        for idx, dat in enumerate(DATA):\n",
    "            new_name_data = FOLDER_OUT + \"new_data/\" + \"data\" + \"_\" + str(idx)\n",
    "            write(new_name_data + \".wav\", rate, data=dat)\n",
    "            save_data([LABEL[idx]], new_name_data + \".csv\")\n",
    "\n",
    "    # convirtiendo a numpy los datos\n",
    "    DATA = np.array(DATA, dtype=float)\n",
    "    LABEL = np.array(LABEL, dtype=float)\n",
    "\n",
    "    return DATA, LABEL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1727\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/media/wisrovi/J/TFM/2022/dataset/archive/musicnet/tf/libraries/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_28759/154304909.py\", line 1, in <cell line: 1>\n",
      "    DATA, LABEL = files_to_data(TRAIN, buscar_todos_label=True)\n",
      "  File \"/tmp/ipykernel_28759/4200871736.py\", line 9, in cronometro\n",
      "    salida = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_28759/2858362108.py\", line 18, in files_to_data\n",
      "    caracteristicas = processAudio.get_all(id_audio)  # Extrayendo caracteristicas audios, salen 26 caracteristicas\n",
      "  File \"/tmp/ipykernel_28759/9644389.py\", line 79, in get_all\n",
      "    self.get_ancho_banda_espectral()\n",
      "  File \"/tmp/ipykernel_28759/9644389.py\", line 50, in get_ancho_banda_espectral\n",
      "    self.spec_bw = librosa.feature.spectral_bandwidth(y=self.data, sr=self.sr)\n",
      "  File \"/media/wisrovi/J/TFM/2022/dataset/archive/musicnet/tf/libraries/venv/lib/python3.8/site-packages/librosa/util/decorators.py\", line 88, in inner_f\n",
      "  File \"/media/wisrovi/J/TFM/2022/dataset/archive/musicnet/tf/libraries/venv/lib/python3.8/site-packages/librosa/feature/spectral.py\", line 352, in spectral_bandwidth\n",
      "  File \"/media/wisrovi/J/TFM/2022/dataset/archive/musicnet/tf/libraries/venv/lib/python3.8/site-packages/librosa/util/decorators.py\", line 88, in inner_f\n",
      "  File \"/media/wisrovi/J/TFM/2022/dataset/archive/musicnet/tf/libraries/venv/lib/python3.8/site-packages/librosa/feature/spectral.py\", line 196, in spectral_centroid\n",
      "    Parameters\n",
      "  File \"/media/wisrovi/J/TFM/2022/dataset/archive/musicnet/tf/libraries/venv/lib/python3.8/site-packages/librosa/util/decorators.py\", line 88, in inner_f\n",
      "  File \"/media/wisrovi/J/TFM/2022/dataset/archive/musicnet/tf/libraries/venv/lib/python3.8/site-packages/librosa/util/utils.py\", line 955, in normalize\n",
      "    2. `x[n] >= mean(x[n - pre_avg:n + post_avg]) + delta`\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/wisrovi/J/TFM/2022/dataset/archive/musicnet/tf/libraries/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 1993, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/media/wisrovi/J/TFM/2022/dataset/archive/musicnet/tf/libraries/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/media/wisrovi/J/TFM/2022/dataset/archive/musicnet/tf/libraries/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/media/wisrovi/J/TFM/2022/dataset/archive/musicnet/tf/libraries/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/media/wisrovi/J/TFM/2022/dataset/archive/musicnet/tf/libraries/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/media/wisrovi/J/TFM/2022/dataset/archive/musicnet/tf/libraries/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/media/wisrovi/J/TFM/2022/dataset/archive/musicnet/tf/libraries/venv/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/media/wisrovi/J/TFM/2022/dataset/archive/musicnet/tf/libraries/venv/lib/python3.8/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/media/wisrovi/J/TFM/2022/dataset/archive/musicnet/tf/libraries/venv/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/media/wisrovi/J/TFM/2022/dataset/archive/musicnet/tf/libraries/venv/lib/python3.8/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/media/wisrovi/J/TFM/2022/dataset/archive/musicnet/tf/libraries/venv/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/media/wisrovi/J/TFM/2022/dataset/archive/musicnet/tf/libraries/venv/lib/python3.8/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/media/wisrovi/J/TFM/2022/dataset/archive/musicnet/tf/libraries/venv/lib/python3.8/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "DATA, LABEL = files_to_data(TRAIN, buscar_todos_label=True)\n",
    "\n",
    "print(len(DATA), len(LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizando y aplicando PCA\n",
    "pca_pipe.fit(DATA)\n",
    "pickle.dump(pca_pipe, open(FOLDER_SAVE_NORMALIZADOR_PCA,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_datos_para_modelo(datos):\n",
    "    normalizador_pca = pickle.load(open(FOLDER_SAVE_NORMALIZADOR_PCA, 'rb'))\n",
    "    x_for_model = normalizador_pca.transform(X=datos)\n",
    "    return x_for_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = preparar_datos_para_modelo(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original vector size: {len(DATA[0])} -> New vector size {len(x_for_model[0])} ({int(MINIMA_VARIANA_EXPLICADA*100)}% información mantenida)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardando datos\n",
    "save_data(DATA, FOLDER_TRAIN_DATA)\n",
    "save_data(LABEL, FOLDER_TRAIN_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = lambda lst: int((sum(lst) / len(lst)) * 100) / 100\n",
    "\n",
    "def calcular_porcentajes_aciertos(y_f, y_t):\n",
    "    verdaderos = dict()\n",
    "    falsos = dict()\n",
    "    for j in range(y_f.shape[1]):\n",
    "        verdaderos[j] = 0\n",
    "        falsos[j] = 0\n",
    "\n",
    "    for i in range(y_f.shape[0]):\n",
    "        for j in range(y_f.shape[1]):\n",
    "            if y_f[i][j] == y_t[i][j]:\n",
    "                verdaderos[j] += 1\n",
    "            else:\n",
    "                falsos[j] += 1\n",
    "\n",
    "    for j in range(y_f.shape[1]):\n",
    "        # y_final.shape[1] -> 100%\n",
    "        # verdaderos[j]    -> X\n",
    "        verdaderos[j] = int(verdaderos[j] * 100 / y_f.shape[0])\n",
    "        falsos[j] = int(falsos[j] * 100 / y_f.shape[0])\n",
    "\n",
    "    return verdaderos, falsos, str(mean([v for i, v in verdaderos.items()])) + \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "grid = GridSearchCV(\n",
    "          estimator = RandomForestClassifier(),\n",
    "          param_grid={},\n",
    "          cv = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(DATA, LABEL, test_size=0.1)  # 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenando\n",
    "grid.fit(X_train, y_train)\n",
    "model = grid.best_estimator_\n",
    "pickle.dump(model, open(FOLDER_MODEL, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final = model.predict(X_valid)\n",
    "print(\"ACC\", metrics.accuracy_score(y_valid, y_final))\n",
    "print(\"PREC\", metrics.precision_score(y_valid, y_final, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTEAR EL MODELO\n",
    "model = pickle.load(open(FOLDER_MODEL, 'rb'))\n",
    "\n",
    "DATA, LABEL = files_to_data(TEST, save_new_data=True)\n",
    "DATA = preparar_datos_para_modelo(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardando datos\n",
    "save_data(DATA, FOLDER_TEST_DATA)\n",
    "save_data(LABEL, FOLDER_TEST_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final = model.predict(DATA)\n",
    "print(\"ACC\", metrics.accuracy_score(LABEL, y_final))\n",
    "print(\"PREC\", metrics.precision_score(LABEL, y_final, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
